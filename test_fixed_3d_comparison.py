#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤æ¶æ„çš„3Då¯¹æ¯”å®éªŒ
å…³é”®ä¿®å¤ï¼š
1. CFTä½¿ç”¨æ›´å¤šæ¨¡æ€ (4x4x4 è€Œä¸æ˜¯ 2x2x2)
2. ç©ºé—´æ„ŸçŸ¥çš„æ®‹å·®ä¿®æ­£ (è€Œä¸æ˜¯å…¨å±€æ ‡é‡)
3. å­¦ä¹ çš„æ®‹å·®æƒé‡ç»„åˆ
4. æ›´é²æ£’çš„CFTå®ç°
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import h5py
import json
import os
from datetime import datetime
from timeit import default_timer

# å¯¼å…¥ä¿®å¤çš„æ¨¡å‹
from fourier_3d_clean import FNO3d
from fourier_3d_cft_residual_fixed import FNO_RC_3D_Fixed
from utilities3 import LpLoss, count_params, UnitGaussianNormalizer
from Adam import Adam

################################################################
# æ•°æ®åŠ è½½ - å¤ç”¨ä¹‹å‰çš„å‡½æ•°
################################################################
def load_3d_data_efficient(data_path, ntrain=800, ntest=100, T_in=10, T_out=20):
    """å†…å­˜é«˜æ•ˆçš„æ•°æ®åŠ è½½"""
    print(f"ğŸ“ æ­£åœ¨åŠ è½½æ•°æ®: {data_path}")
    
    try:
        print("â³ æ­£åœ¨è¯»å–.matæ–‡ä»¶ (MATLAB v7.3æ ¼å¼)...")
        with h5py.File(data_path, 'r') as f:
            u_field = f['u'][:]  # [T, H, W, N] -> [50, 64, 64, 10000]
        
        print(f"âœ… åŸå§‹æ•°æ®å½¢çŠ¶: {u_field.shape}")
        
        # è½¬æ¢ä¸ºtensorå¹¶è°ƒæ•´æ ¼å¼: [T, H, W, N] -> [N, H, W, T]
        print("ğŸ”„ æ­£åœ¨è½¬æ¢æ•°æ®æ ¼å¼...")
        u_field = torch.from_numpy(u_field).float()
        u_field = u_field.permute(3, 1, 2, 0)  # [10000, 64, 64, 50]
        print(f"âœ… è½¬æ¢åæ•°æ®å½¢çŠ¶: {u_field.shape}")
        
        # æ§åˆ¶æ ·æœ¬æ•°é‡ä»¥èŠ‚çœå†…å­˜
        total_samples = u_field.shape[0]
        ntrain_actual = min(total_samples - 150, ntrain)
        ntest_actual = min(total_samples - ntrain_actual, ntest)
        
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples}, è®­ç»ƒ: {ntrain_actual}, æµ‹è¯•: {ntest_actual}")
        
        # æ£€æŸ¥æ—¶é—´æ­¥
        if u_field.shape[-1] < T_in + T_out:
            print(f"âŒ æ—¶é—´æ­¥ä¸è¶³: éœ€è¦ {T_in + T_out}, å®é™… {u_field.shape[-1]}")
            return None
        
        print("ğŸ”„ æ­£åœ¨åˆ†å‰²æ•°æ®...")
        train_a = u_field[:ntrain_actual, ..., :T_in]
        train_u = u_field[:ntrain_actual, ..., T_in:T_in + T_out]
        
        test_a = u_field[-ntest_actual:, ..., :T_in]
        test_u = u_field[-ntest_actual:, ..., T_in:T_in + T_out]

        print(f"âœ… æ•°æ®å½¢çŠ¶: train_a: {train_a.shape}, train_u: {train_u.shape}")
        print(f"âœ… æœ€ç»ˆæ ·æœ¬æ•°: ntrain={ntrain_actual}, ntest={ntest_actual}")
        
        # é‡Šæ”¾åŸå§‹æ•°æ®
        del u_field
        import gc
        gc.collect()
        
        return train_a, train_u, test_a, test_u, ntrain_actual, ntest_actual
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def preprocess_3d_data_sequence(train_a, train_u, test_a, test_u, T_in, T_out, device):
    """å®Œæ•´åºåˆ—é¢„æµ‹çš„æ•°æ®é¢„å¤„ç†"""
    
    S1, S2 = train_a.shape[1], train_a.shape[2]
    ntrain_actual, ntest_actual = train_a.shape[0], test_a.shape[0]
    
    # æ ‡å‡†åŒ–è¾“å…¥
    a_normalizer = UnitGaussianNormalizer(train_a)
    train_a = a_normalizer.encode(train_a)
    test_a = a_normalizer.encode(test_a)

    # æ ‡å‡†åŒ–å®Œæ•´åºåˆ—è¾“å‡º
    y_normalizer = UnitGaussianNormalizer(train_u)
    train_u_normalized = y_normalizer.encode(train_u)
    y_normalizer.to(device)
    
    # æ•°æ®æ ¼å¼è½¬æ¢
    train_a_fno = train_a.reshape(ntrain_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    test_a_fno = test_a.reshape(ntest_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    
    train_a_rc = train_a.reshape(ntrain_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    test_a_rc = test_a.reshape(ntest_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    
    print(f"é¢„å¤„ç†å®Œæˆï¼ˆä¿®å¤æ¶æ„ç‰ˆæœ¬ï¼‰:")
    print(f"  FNOè¾“å…¥: {train_a_fno.shape}, ç›®æ ‡: {train_u_normalized.shape}")
    print(f"  FNO_RC_Fixedè¾“å…¥: {train_a_rc.shape}, ç›®æ ‡: {train_u_normalized.shape}")
    
    return (train_a_fno, train_u_normalized, test_a_fno, test_u, 
            train_a_rc, test_a_rc, y_normalizer, S1, S2)

################################################################
# è®­ç»ƒå‡½æ•°
################################################################
def train_model_fixed(model, model_name, train_loader, test_loader, y_normalizer, device, ntrain_actual, ntest_actual, epochs=100):
    """ä¿®å¤æ¶æ„çš„è®­ç»ƒå‡½æ•°"""
    print(f"\nğŸ”§ Training {model_name} (Fixed Architecture)...")
    print(f"Parameters: {count_params(model):,}")
    
    model.to(device)
    optimizer = Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)
    loss_func = LpLoss(size_average=False)
    
    train_losses = []
    test_losses = []
    
    # æ—©åœæœºåˆ¶
    best_test_loss = float('inf')
    patience = 15
    patience_counter = 0
    
    for ep in range(epochs):
        model.train()
        t1 = default_timer()
        train_l2 = 0
        
        for batch_idx, (x, y) in enumerate(train_loader):
            x, y = x.to(device), y.to(device)
            
            optimizer.zero_grad()
            
            if model_name == 'FNO3d':
                # FNO3d: æ·»åŠ ç½‘æ ¼åæ ‡
                grid = create_grid_for_fno3d(x.shape, device)
                x_with_grid = torch.cat((x, grid), dim=-1)
                out = model(x_with_grid).squeeze(-1)
            elif model_name == 'FNO_RC_3D_Fixed':
                # ä¿®å¤çš„FNO_RC_3D
                out = model(x).squeeze(-1)
                
                # ç›‘æ§CFTè·¯å¾„çš„å­¦ä¹ æƒ…å†µ
                if ep % 20 == 0 and batch_idx == 0:
                    # æ£€æŸ¥æ®‹å·®æƒé‡çš„å­¦ä¹ æƒ…å†µ
                    residual_weights = [layer.residual_weight.item() for layer in [model.conv0, model.conv1, model.conv2, model.conv3]]
                    print(f"  æ®‹å·®æƒé‡: {residual_weights}")
                    print(f"  è¾“å‡ºèŒƒå›´: min={out.min().item():.6f}, max={out.max().item():.6f}, std={out.std().item():.6f}")
            
            # å®Œæ•´åºåˆ—æŸå¤±è®¡ç®—
            loss_normalized = loss_func(out, y)
            loss_normalized.backward()
            optimizer.step()
            
            # è®°å½•æŸå¤± - ä½¿ç”¨çœŸå®å°ºåº¦æ•°æ®
            with torch.no_grad():
                out_decoded = y_normalizer.decode(out)
                y_decoded = y_normalizer.decode(y)
                loss_real_scale = loss_func(out_decoded, y_decoded)
                train_l2 += loss_real_scale.item()
        
        scheduler.step()
        
        # æµ‹è¯•
        model.eval()
        test_l2 = 0.0
        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(device), y.to(device)
                
                if model_name == 'FNO3d':
                    grid = create_grid_for_fno3d(x.shape, device)
                    x_with_grid = torch.cat((x, grid), dim=-1)
                    out = model(x_with_grid).squeeze(-1)
                elif model_name == 'FNO_RC_3D_Fixed':
                    out = model(x).squeeze(-1)
                
                # å®Œæ•´åºåˆ—æµ‹è¯•æŸå¤±
                out_decoded = y_normalizer.decode(out)
                y_decoded = y_normalizer.decode(y)
                test_l2 += loss_func(out_decoded, y_decoded).item()
        
        train_l2 /= ntrain_actual
        test_l2 /= ntest_actual
        
        train_losses.append(train_l2)
        test_losses.append(test_l2)
        
        # æ—©åœæ£€æŸ¥
        if test_l2 < best_test_loss:
            best_test_loss = test_l2
            patience_counter = 0
        else:
            patience_counter += 1
            
        if ep % 10 == 0:
            print(f'Epoch {ep+1}/{epochs}: Train {train_l2:.6f}, Test {test_l2:.6f}')
        
        # æ—©åœ
        if patience_counter >= patience:
            print(f"ğŸ›‘ æ—©åœ: æµ‹è¯•æŸå¤±åœ¨{patience}ä¸ªepochå†…æ²¡æœ‰æ”¹å–„")
            break
    
    return model, train_losses, test_losses

def create_grid_for_fno3d(shape, device):
    """ä¸ºFNO3dåˆ›å»ºç½‘æ ¼åæ ‡"""
    B, H, W, T_dim, _ = shape
    
    h_coords = torch.linspace(0, 1, H, device=device)
    w_coords = torch.linspace(0, 1, W, device=device)
    t_coords = torch.linspace(0, 1, T_dim, device=device)
    
    hh, ww, tt = torch.meshgrid(h_coords, w_coords, t_coords, indexing='ij')
    grid = torch.stack([hh, ww, tt], dim=-1).unsqueeze(0).repeat(B, 1, 1, 1, 1)
    
    return grid

################################################################
# ä¸»å‡½æ•°
################################################################
def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"ğŸ“± GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    print("ğŸ”§ è®¾ç½®Colabç¯å¢ƒ...")
    
    # å‚æ•°è®¾ç½®
    data_path = '/content/drive/MyDrive/ns_V1e-4_N10000_T30.mat'
    ntrain, ntest = 600, 80        # è¿›ä¸€æ­¥å‡å°‘æ ·æœ¬æ•°ä»¥èŠ‚çœå†…å­˜
    T_in, T_out = 10, 20           # ä¿æŒå®Œæ•´åºåˆ—é¢„æµ‹
    modes = 8
    width = 20
    batch_size = 6                 # è¿›ä¸€æ­¥å‡å°batch_size
    epochs = 100
    
    print("ğŸš€ å¼€å§‹3Då¯¹æ¯”å®éªŒ - ä¿®å¤æ¶æ„ç‰ˆæœ¬")
    print(f"ğŸ“‹ å®éªŒå‚æ•°: epochs={epochs}, batch_size={batch_size}")
    print(f"ğŸ“Š æ•°æ®å‚æ•°: ntrain={ntrain}, ntest={ntest}, T_in={T_in}, T_out={T_out}")
    print("ğŸ¯ å…³é”®ä¿®å¤: CFTç©ºé—´æ„ŸçŸ¥æ®‹å·®ä¿®æ­£ + å­¦ä¹ æƒé‡ç»„åˆ")
    
    # æ•°æ®åŠ è½½
    print("\nğŸ“ æ­¥éª¤1: æ•°æ®åŠ è½½")
    data = load_3d_data_efficient(data_path, ntrain, ntest, T_in, T_out)
    if data is None:
        return
    
    train_a, train_u, test_a, test_u, ntrain_actual, ntest_actual = data
    
    # æ•°æ®é¢„å¤„ç†
    print("\nğŸ”„ æ­¥éª¤2: æ•°æ®é¢„å¤„ç†")
    processed_data = preprocess_3d_data_sequence(train_a, train_u, test_a, test_u, T_in, T_out, device)
    (train_a_fno, train_u, test_a_fno, test_u, 
     train_a_rc, test_a_rc, y_normalizer, S1, S2) = processed_data
    
    # æ•°æ®åŠ è½½å™¨
    train_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(train_a_fno, train_u), 
        batch_size=batch_size, shuffle=True
    )
    test_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(test_a_fno, test_u), 
        batch_size=batch_size, shuffle=False
    )
    
    # æ¨¡å‹å®šä¹‰ - å¯¹æ¯”åŸå§‹FNOå’Œä¿®å¤çš„FNO_RC
    models = {
        'FNO3d': FNO3d(modes, modes, modes, width, in_dim=13, out_dim=1),
        'FNO_RC_3D_Fixed': FNO_RC_3D_Fixed(modes, modes, modes, width, in_channels=T_in, out_channels=1),
    }
    
    print(f"ğŸ“Š æ¨¡å‹é…ç½®:")
    for name, model in models.items():
        print(f"  {name}: {count_params(model):,} å‚æ•°")
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    print("\nğŸ‹ï¸ æ­¥éª¤3: å¼€å§‹è®­ç»ƒæ¨¡å‹")
    results = {}
    for model_name, model in models.items():
        trained_model, train_losses, test_losses = train_model_fixed(
            model, model_name, train_loader, test_loader, y_normalizer, device, ntrain_actual, ntest_actual, epochs
        )
        
        final_test_loss = test_losses[-1]
        results[model_name] = {
            'final_test_loss': final_test_loss,
            'train_losses': train_losses,
            'test_losses': test_losses,
            'parameters': count_params(model)
        }
        print(f"âœ… {model_name}: {final_test_loss:.6f}")
    
    # ç»“æœå¯¹æ¯”
    print(f"\nğŸ† 3Då®éªŒç»“æœ (ä¿®å¤æ¶æ„ - {epochs} epochs):")
    print("-" * 60)
    
    # æŒ‰æ€§èƒ½æ’åºæ˜¾ç¤º
    sorted_results = sorted(results.items(), key=lambda x: x[1]['final_test_loss'])
    
    for i, (name, result) in enumerate(sorted_results):
        rank = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰"
        print(f"{rank} {name}: {result['final_test_loss']:.6f} ({result['parameters']:,} å‚æ•°)")
    
    # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
    if len(sorted_results) >= 2:
        best_name, best_result = sorted_results[0]
        baseline_name, baseline_result = sorted_results[1]
        improvement = (baseline_result['final_test_loss'] - best_result['final_test_loss']) / baseline_result['final_test_loss'] * 100
        print(f"\nğŸ“ˆ {best_name} ç›¸å¯¹äº {baseline_name} æ”¹è¿›: {improvement:.2f}%")
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = '/content/drive/MyDrive/FNO_RC_Experiments/'
    os.makedirs(results_dir, exist_ok=True)
    results_file = f'{results_dir}/fixed_architecture_3d_comparison_{timestamp}.json'
    
    serializable_results = {}
    for name, result in results.items():
        serializable_results[name] = {
            'final_test_loss': float(result['final_test_loss']),
            'parameters': int(result['parameters']),
            'train_losses': [float(x) for x in result['train_losses']],
            'test_losses': [float(x) for x in result['test_losses']]
        }
    
    with open(results_file, 'w') as f:
        json.dump(serializable_results, f, indent=2)
    
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    print("ğŸ‰ ä¿®å¤æ¶æ„3Då¯¹æ¯”å®éªŒå®Œæˆï¼")
    print("\nğŸ“ æ¶æ„ä¿®å¤è¦ç‚¹:")
    print("   âœ… CFTä½¿ç”¨4Ã—4Ã—4æ¨¡æ€ (è€Œä¸æ˜¯2Ã—2Ã—2)")
    print("   âœ… ç©ºé—´æ„ŸçŸ¥çš„3Då·ç§¯æ®‹å·®ä¿®æ­£")
    print("   âœ… å­¦ä¹ çš„æ®‹å·®æƒé‡ç»„åˆ")
    print("   âœ… æ›´é²æ£’çš„CFTå®ç°å’Œé”™è¯¯å¤„ç†")

if __name__ == "__main__":
    main()
