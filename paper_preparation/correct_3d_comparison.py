#!/usr/bin/env python3
"""
æ­£ç¡®çš„3Då¯¹æ¯”å®éªŒ - ä¸¥æ ¼åŸºäºç°æœ‰æ¶æ„ï¼Œç»Ÿä¸€è¾“å…¥è¾“å‡ºæ ¼å¼
å¯¹æ¯”: FNO3d vs FNO_RC_3D vs 2024æœ€æ–°æ¨¡å‹å˜ä½“
æ ¸å¿ƒä¿®å¤ï¼šç»Ÿä¸€æ•°æ®æ ¼å¼ï¼Œç¡®ä¿å…¬å¹³å¯¹æ¯”
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import scipy.io
import h5py
import json
import os
from datetime import datetime
from timeit import default_timer

# å¯¼å…¥ç°æœ‰çš„æ¨¡å‹å’Œå·¥å…·
from fourier_3d_clean import FNO3d
from fourier_3d_cft_residual import FNO_RC_3D
from utilities3 import LpLoss, count_params, UnitGaussianNormalizer, MatReader
from Adam import Adam

################################################################
# æ•°æ®åŠ è½½ - ä¸ç°æœ‰è®­ç»ƒè„šæœ¬å®Œå…¨ä¸€è‡´
################################################################
def load_3d_data(data_path, ntrain=1000, ntest=200, T_in=10, T_out=20):
    """å¿«é€ŸåŠ è½½3Dæ•°æ® - ä½¿ç”¨h5pyè¯»å–MATLAB v7.3æ–‡ä»¶"""
    print(f"ğŸ“ æ­£åœ¨åŠ è½½æ•°æ®: {data_path}")
    
    try:
        print("â³ æ­£åœ¨è¯»å–.matæ–‡ä»¶ (MATLAB v7.3æ ¼å¼)...")
        # ä½¿ç”¨h5pyè¯»å–MATLAB v7.3æ ¼å¼æ–‡ä»¶
        import h5py
        with h5py.File(data_path, 'r') as f:
            u_field = f['u'][:]  # [T, H, W, N] -> [50, 64, 64, 10000]
        
        print(f"âœ… åŸå§‹æ•°æ®å½¢çŠ¶: {u_field.shape}")
        
        # è½¬æ¢ä¸ºtensorå¹¶è°ƒæ•´æ ¼å¼: [T, H, W, N] -> [N, H, W, T]
        print("ğŸ”„ æ­£åœ¨è½¬æ¢æ•°æ®æ ¼å¼...")
        u_field = torch.from_numpy(u_field).float()
        u_field = u_field.permute(3, 1, 2, 0)  # [10000, 64, 64, 50]
        print(f"âœ… è½¬æ¢åæ•°æ®å½¢çŠ¶: {u_field.shape}")
        
        # åŠ¨æ€ç¡®å®šå®é™…å¯ç”¨çš„è®­ç»ƒå’Œæµ‹è¯•æ ·æœ¬æ•°
        total_samples = u_field.shape[0]
        ntrain_actual = min(total_samples - 100, ntrain)  # ç¡®ä¿è‡³å°‘ç•™100ä¸ªç»™æµ‹è¯•
        ntest_actual = min(total_samples - ntrain_actual, ntest)
        
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples}, è®­ç»ƒ: {ntrain_actual}, æµ‹è¯•: {ntest_actual}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ—¶é—´æ­¥
        if u_field.shape[-1] < T_in + T_out:
            print(f"âŒ æ—¶é—´æ­¥ä¸è¶³: éœ€è¦ {T_in + T_out}, å®é™… {u_field.shape[-1]}")
            return None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬
        if ntest_actual <= 0:
            print(f"âš ï¸ æµ‹è¯•æ ·æœ¬ä¸è¶³ï¼Œè°ƒæ•´å‚æ•°...")
            ntest_actual = max(50, total_samples // 10)  # è‡³å°‘50ä¸ªæµ‹è¯•æ ·æœ¬
            ntrain_actual = total_samples - ntest_actual
        
        print("ğŸ”„ æ­£åœ¨åˆ†å‰²è®­ç»ƒæ•°æ®...")
        train_a = u_field[:ntrain_actual, ..., :T_in]
        train_u = u_field[:ntrain_actual, ..., T_in:T_in + T_out]
        
        print("ğŸ”„ æ­£åœ¨åˆ†å‰²æµ‹è¯•æ•°æ®...")
        test_a = u_field[-ntest_actual:, ..., :T_in]
        test_u = u_field[-ntest_actual:, ..., T_in:T_in + T_out]

        print(f"âœ… æ•°æ®å½¢çŠ¶: train_a: {train_a.shape}, train_u: {train_u.shape}")
        print(f"âœ… æœ€ç»ˆæ ·æœ¬æ•°: ntrain={ntrain_actual}, ntest={ntest_actual}")
        
        # æ¸…ç†åŸå§‹æ•°æ®ä»¥é‡Šæ”¾å†…å­˜
        del u_field
        import gc
        gc.collect()
        
        return train_a, train_u, test_a, test_u, ntrain_actual, ntest_actual
        
    except KeyboardInterrupt:
        print("âŒ æ•°æ®åŠ è½½è¢«ç”¨æˆ·ä¸­æ–­")
        raise
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

################################################################
# æ•°æ®é¢„å¤„ç† - ä¸ç°æœ‰è„šæœ¬å®Œå…¨ä¸€è‡´
################################################################
def preprocess_3d_data(train_a, train_u, test_a, test_u, T_in, T_out, device):
    """ç»Ÿä¸€çš„æ•°æ®é¢„å¤„ç† - ä¸ºäº†å…¬å¹³å¯¹æ¯”ï¼Œæ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„ç›®æ ‡"""
    
    S1, S2 = train_a.shape[1], train_a.shape[2]
    ntrain_actual, ntest_actual = train_a.shape[0], test_a.shape[0]
    
    # æ ‡å‡†åŒ–è¾“å…¥
    a_normalizer = UnitGaussianNormalizer(train_a)
    train_a = a_normalizer.encode(train_a)
    test_a = a_normalizer.encode(test_a)

    # ç»Ÿä¸€ç›®æ ‡ï¼šé¢„æµ‹å…³é”®æ—¶é—´ç‚¹ - ä¸­é—´ç‚¹å’Œæœ€åä¸€ä¸ªæ—¶é—´æ­¥
    # æŠ½å–æ—¶é—´ç‚¹ï¼šä¸­é—´ç‚¹(T_out//2)å’Œæœ€åä¸€ä¸ªæ—¶é—´æ­¥(T_out-1)
    mid_idx = T_out // 2
    last_idx = T_out - 1
    
    train_u_mid = train_u[..., mid_idx]  # [N, H, W] - ä¸­é—´æ—¶é—´ç‚¹
    train_u_last = train_u[..., last_idx]  # [N, H, W] - æœ€åæ—¶é—´ç‚¹
    test_u_mid = test_u[..., mid_idx]  # [N, H, W]
    test_u_last = test_u[..., last_idx]  # [N, H, W]
    
    # åˆå¹¶å…³é”®æ—¶é—´ç‚¹ä½œä¸ºç›®æ ‡
    train_u_target = torch.stack([train_u_mid, train_u_last], dim=-1)  # [N, H, W, 2]
    test_u_target = torch.stack([test_u_mid, test_u_last], dim=-1)  # [N, H, W, 2]
    
    # æ ‡å‡†åŒ–ç›®æ ‡
    y_normalizer = UnitGaussianNormalizer(train_u_target)
    train_u_normalized = y_normalizer.encode(train_u_target)
    y_normalizer.to(device)
    
    # === FNO3dæ•°æ®æ ¼å¼ ===
    # è¾“å…¥: [N, H, W, T_out, T_in] (åœ¨æ—¶é—´ç½‘æ ¼ä¸Šé‡å¤è¾“å…¥)
    train_a_fno = train_a.reshape(ntrain_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    test_a_fno = test_a.reshape(ntest_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    
    # === FNO_RC_3Dæ•°æ®æ ¼å¼ ===  
    # è¾“å…¥: [N, H, W, T_out, T_in] (ä¸åŸå§‹è®­ç»ƒè„šæœ¬å®Œå…¨ä¸€è‡´ï¼)
    train_a_rc = train_a.reshape(ntrain_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    test_a_rc = test_a.reshape(ntest_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    
    print(f"é¢„å¤„ç†å®Œæˆ:")
    print(f"  FNOè¾“å…¥: {train_a_fno.shape}, ç›®æ ‡: {train_u_normalized.shape}")
    print(f"  FNO_RCè¾“å…¥: {train_a_rc.shape}, ç›®æ ‡: {train_u_normalized.shape}")
    
    return (train_a_fno, train_u_normalized, test_a_fno, test_u_target, 
            train_a_rc, test_a_rc, y_normalizer, S1, S2)

################################################################
# B-DeepONet 3Dæ¨¡å‹ - ç®€åŒ–ä½†æœ‰æ•ˆçš„å®ç°
################################################################
class BDeepONet3D_Simple(nn.Module):
    def __init__(self, modes1, modes2, modes3, width, T_in=10, T_out=1):
        super(BDeepONet3D_Simple, self).__init__()
        self.T_in = T_in
        self.T_out = T_out
        self.width = width
        
        # Branchç½‘ç»œ - å¤„ç†è¾“å…¥å‡½æ•°
        self.branch_net = nn.Sequential(
            nn.Linear(T_in + 3, width),  # T_inä¸ªæ—¶é—´æ­¥ + 3ä¸ªåæ ‡
            nn.GELU(),
            nn.Linear(width, width),
            nn.GELU(),
            nn.Linear(width, width)
        )
        
        # Trunkç½‘ç»œ - å¤„ç†æŸ¥è¯¢ç‚¹
        self.trunk_net = nn.Sequential(
            nn.Linear(3, width),  # 3ä¸ªåæ ‡
            nn.GELU(),
            nn.Linear(width, width),
            nn.GELU(),
            nn.Linear(width, width)
        )
        
        # è¾“å‡ºå±‚ - é¢„æµ‹å®Œæ•´æ—¶é—´åºåˆ—
        self.output_layer = nn.Linear(width, T_out)

    def forward(self, x):
        # x: [B, H, W, T_out, T_in] (ä¸FNOä¿æŒä¸€è‡´çš„è¾“å…¥æ ¼å¼)
        B, H, W, T_out_dim, T_in_dim = x.shape  # T_out_dim = T_out = 20
        
        # ç”Ÿæˆç½‘æ ¼åæ ‡
        h_coords = torch.linspace(0, 1, H, device=x.device)
        w_coords = torch.linspace(0, 1, W, device=x.device)
        t_coords = torch.linspace(0, 1, T_out_dim, device=x.device)
        
        hh, ww, tt = torch.meshgrid(h_coords, w_coords, t_coords, indexing='ij')
        coords = torch.stack([hh, ww, tt], dim=-1).unsqueeze(0).repeat(B, 1, 1, 1, 1)
        
        # Branchç½‘ç»œè¾“å…¥ï¼šå‡½æ•°å€¼ + åæ ‡
        x_with_coords = torch.cat([x, coords], dim=-1)  # [B, H, W, T_out, T_in + 3]
        branch_out = self.branch_net(x_with_coords)  # [B, H, W, T_out, width]
        
        # Trunkç½‘ç»œè¾“å…¥ï¼šåæ ‡
        trunk_out = self.trunk_net(coords)  # [B, H, W, T_out, width]
        
        # DeepONetç»„åˆ
        combined = branch_out * trunk_out  # [B, H, W, T_out, width]
        output = self.output_layer(combined)  # [B, H, W, T_out, T_out]
        
        # å¯¹è§’çº¿æå– - æ¯ä¸ªæ—¶é—´ä½ç½®é¢„æµ‹å¯¹åº”çš„è¾“å‡º
        B, H, W, T, _ = output.shape
        output_diag = torch.zeros(B, H, W, T, device=output.device)
        for t in range(T):
            output_diag[:, :, :, t] = output[:, :, :, t, t]
        
        return output_diag  # [B, H, W, T_out]

################################################################
# è®­ç»ƒå‡½æ•° - ä¸ç°æœ‰è„šæœ¬ä¸€è‡´
################################################################
def train_model(model, model_name, train_loader, test_loader, y_normalizer, device, ntrain_actual, ntest_actual, epochs=100, mid_idx=5, last_idx=9):
    """ç»Ÿä¸€çš„è®­ç»ƒå‡½æ•°"""
    print(f"\nğŸ”§ Training {model_name}...")
    print(f"Parameters: {count_params(model):,}")
    
    model.to(device)
    # ä½¿ç”¨ç»Ÿä¸€çš„å­¦ä¹ ç‡è®¾ç½® - ä¸ä¹‹å‰å®éªŒä¸€è‡´
    optimizer = Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)
    loss_func = LpLoss(size_average=False)
    
    train_losses = []
    test_losses = []
    
    # æ—©åœæœºåˆ¶
    best_test_loss = float('inf')
    patience = 10
    patience_counter = 0
    
    for ep in range(epochs):
        model.train()
        t1 = default_timer()
        train_l2 = 0
        
        for batch_idx, (x, y) in enumerate(train_loader):
            x, y = x.to(device), y.to(device)
            
            optimizer.zero_grad()
            
            if model_name == 'FNO3d':
                # FNO3d: æ·»åŠ ç½‘æ ¼åæ ‡ï¼Œè¾“å‡ºå…³é”®æ—¶é—´ç‚¹
                grid = create_grid_for_fno3d(x.shape, device)
                x_with_grid = torch.cat((x, grid), dim=-1)  # [B, H, W, T_out, 13]
                out_full = model(x_with_grid)  # [B, H, W, T_out, 1]
                out_full = out_full.squeeze(-1)  # [B, H, W, T_out]
                # æŠ½å–å…³é”®æ—¶é—´ç‚¹
                out = torch.stack([out_full[..., mid_idx], out_full[..., last_idx]], dim=-1)  # [B, H, W, 2]
            elif model_name == 'FNO_RC_3D':
                # FNO_RC_3D: è¾“å‡ºå…³é”®æ—¶é—´ç‚¹
                out_full = model(x)  # [B, H, W, T_out, 1]
                out_full = out_full.squeeze(-1)  # [B, H, W, T_out]
                # æŠ½å–å…³é”®æ—¶é—´ç‚¹
                out = torch.stack([out_full[..., mid_idx], out_full[..., last_idx]], dim=-1)  # [B, H, W, 2]
                
                # è°ƒè¯•ä¿¡æ¯ï¼šç›‘æ§CFTè·¯å¾„çš„è¾“å‡ºèŒƒå›´
                if ep % 10 == 0 and batch_idx == 0:
                    print(f"  FNO_RC_3D è¾“å‡ºèŒƒå›´: min={out.min().item():.6f}, max={out.max().item():.6f}, std={out.std().item():.6f}")
            else:
                # å…¶ä»–æ¨¡å‹: ç¡®ä¿è¾“å‡ºæ ¼å¼ä¸€è‡´
                out = model(x)  # [B, H, W]
            
            # æ­£ç¡®çš„è®­ç»ƒé€»è¾‘ï¼šåå‘ä¼ æ’­ä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®ï¼Œè®°å½•ä½¿ç”¨çœŸå®å°ºåº¦æ•°æ®
            # 1. åå‘ä¼ æ’­æŸå¤± - ä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®ä¿è¯è®­ç»ƒç¨³å®šæ€§
            loss_normalized = loss_func(out, y)
            loss_normalized.backward()
            optimizer.step()
            
            # 2. è®°å½•æŸå¤± - ä½¿ç”¨çœŸå®å°ºåº¦æ•°æ®ï¼Œä¸æµ‹è¯•ä¿æŒä¸€è‡´
            with torch.no_grad():
                out_decoded = y_normalizer.decode(out)
                y_decoded = y_normalizer.decode(y)
                loss_real_scale = loss_func(out_decoded, y_decoded)
                train_l2 += loss_real_scale.item()
        
        scheduler.step()
        
        # æµ‹è¯•
        model.eval()
        test_l2 = 0.0
        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(device), y.to(device)
                
                if model_name == 'FNO3d':
                    # FNO3d: æ·»åŠ ç½‘æ ¼åæ ‡ï¼Œè¾“å‡ºå…³é”®æ—¶é—´ç‚¹
                    grid = create_grid_for_fno3d(x.shape, device)
                    x_with_grid = torch.cat((x, grid), dim=-1)  # [B, H, W, T_out, 13]
                    out_full = model(x_with_grid)  # [B, H, W, T_out, 1]
                    out_full = out_full.squeeze(-1)  # [B, H, W, T_out]
                    # æŠ½å–å…³é”®æ—¶é—´ç‚¹
                    out = torch.stack([out_full[..., mid_idx], out_full[..., last_idx]], dim=-1)  # [B, H, W, 2]
                elif model_name == 'FNO_RC_3D':
                    # FNO_RC_3D: è¾“å‡ºå…³é”®æ—¶é—´ç‚¹
                    out_full = model(x)  # [B, H, W, T_out, 1]
                    out_full = out_full.squeeze(-1)  # [B, H, W, T_out]
                    # æŠ½å–å…³é”®æ—¶é—´ç‚¹
                    out = torch.stack([out_full[..., mid_idx], out_full[..., last_idx]], dim=-1)  # [B, H, W, 2]
                else:
                    # å…¶ä»–æ¨¡å‹: ç¡®ä¿è¾“å‡ºæ ¼å¼ä¸€è‡´
                    out = model(x)  # [B, H, W]
                
                # ç»Ÿä¸€çš„æµ‹è¯•æŸå¤±è®¡ç®— - ä½¿ç”¨çœŸå®å°ºåº¦æ•°æ®
                out_decoded = y_normalizer.decode(out)
                y_decoded = y_normalizer.decode(y)
                test_l2 += loss_func(out_decoded, y_decoded).item()
        
        train_l2 /= ntrain_actual
        test_l2 /= ntest_actual
        
        train_losses.append(train_l2)
        test_losses.append(test_l2)
        
        # æ—©åœæ£€æŸ¥
        if test_l2 < best_test_loss:
            best_test_loss = test_l2
            patience_counter = 0
        else:
            patience_counter += 1
            
        if ep % 5 == 0:  # ğŸ”§ è°ƒè¯•ç‰ˆæœ¬ï¼šæ¯5ä¸ªepochè¾“å‡ºä¸€æ¬¡
            print(f'Epoch {ep+1}/{epochs}: Train {train_l2:.6f}, Test {test_l2:.6f}')
        
        # æ—©åœ
        if patience_counter >= patience:
            print(f"ğŸ›‘ æ—©åœ: æµ‹è¯•æŸå¤±åœ¨{patience}ä¸ªepochå†…æ²¡æœ‰æ”¹å–„")
            break
    
    return model, train_losses, test_losses

################################################################
# ç½‘æ ¼ç”Ÿæˆå‡½æ•° - ä¸ºFNO3dä½¿ç”¨
################################################################
def create_grid_for_fno3d(shape, device):
    """ä¸ºFNO3dåˆ›å»ºç½‘æ ¼åæ ‡ - æŒ‰ç…§ç°æœ‰è„šæœ¬çš„æ–¹å¼"""
    B, H, W, T_dim, _ = shape  # T_dim = T_out = 20
    
    h_coords = torch.linspace(0, 1, H, device=device)
    w_coords = torch.linspace(0, 1, W, device=device)
    t_coords = torch.linspace(0, 1, T_dim, device=device)
    
    hh, ww, tt = torch.meshgrid(h_coords, w_coords, t_coords, indexing='ij')
    grid = torch.stack([hh, ww, tt], dim=-1).unsqueeze(0).repeat(B, 1, 1, 1, 1)
    
    return grid

################################################################
# ä¸»å‡½æ•°
################################################################
def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"ğŸ“± GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # Colabç¯å¢ƒè®¾ç½®
    print("ğŸ”§ è®¾ç½®Colabç¯å¢ƒ...")
    import sys
    sys.path.append('/content')  # ä¿®æ”¹ä¸ºæ­£ç¡®çš„è·¯å¾„
    
    # å‚æ•°è®¾ç½® - å¿«é€Ÿæµ‹è¯•ç‰ˆæœ¬
    data_path = '/content/drive/MyDrive/ns_V1e-4_N10000_T30.mat'
    ntrain, ntest = 500, 100  # å¢åŠ æ ·æœ¬æ•°ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
    T_in, T_out = 10, 10  # ğŸ”§ è°ƒæ•´ï¼šè¾“å…¥10æ­¥ï¼Œé¢„æµ‹çª—å£10æ­¥ï¼ˆæ•°æ®åªæœ‰50ä¸ªæ—¶é—´æ­¥ï¼‰
    modes = 8
    width = 20
    batch_size = 10
    epochs = 50  # å¢åŠ epochsä»¥å……åˆ†è®­ç»ƒCFTè·¯å¾„
    
    # å…³é”®æ—¶é—´ç‚¹ç´¢å¼•
    mid_idx = T_out // 2  # ä¸­é—´ç‚¹
    last_idx = T_out - 1  # æœ€åæ—¶é—´ç‚¹
    
    print("ğŸš€ å¼€å§‹3Då¯¹æ¯”å®éªŒ - å……åˆ†è®­ç»ƒç‰ˆæœ¬")
    print(f"ğŸ“‹ å®éªŒå‚æ•°: epochs={epochs}, batch_size={batch_size}")
    print(f"ğŸ“Š æ•°æ®å‚æ•°: ntrain={ntrain}, ntest={ntest}, T_in={T_in}, T_out={T_out}")
    
    # æ•°æ®åŠ è½½
    print("\nğŸ“ æ­¥éª¤1: æ•°æ®åŠ è½½")
    data = load_3d_data(data_path, ntrain, ntest, T_in, T_out)
    if data is None:
        return
    
    train_a, train_u, test_a, test_u, ntrain_actual, ntest_actual = data
    
    # æ•°æ®é¢„å¤„ç†
    print("\nğŸ”„ æ­¥éª¤2: æ•°æ®é¢„å¤„ç†")
    processed_data = preprocess_3d_data(train_a, train_u, test_a, test_u, T_in, T_out, device)
    (train_a_fno, train_u, test_a_fno, test_u, 
     train_a_rc, test_a_rc, y_normalizer, S1, S2) = processed_data
    
    # æ•°æ®åŠ è½½å™¨ - ç»Ÿä¸€ä½¿ç”¨ç›¸åŒçš„è¾“å…¥æ ¼å¼
    train_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(train_a_fno, train_u), 
        batch_size=batch_size, shuffle=True
    )
    test_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(test_a_fno, test_u), 
        batch_size=batch_size, shuffle=False
    )
    
    # æ¨¡å‹å®šä¹‰ - ç»Ÿä¸€è¾“å‡ºå•ä¸ªæ—¶é—´æ­¥è¿›è¡Œå…¬å¹³å¯¹æ¯”
    models = {
        'FNO3d': FNO3d(modes, modes, modes, width, in_dim=13, out_dim=1),  # è¾“å‡ºå•ä¸ªæ—¶é—´æ­¥
        'FNO_RC_3D': FNO_RC_3D(modes, modes, T_out//2 + 1, width, in_channels=T_in, out_channels=1),  # è¾“å‡ºå•ä¸ªæ—¶é—´æ­¥
        
        # ğŸ”§ TODO: ç¡®è®¤ä¸Šè¿°ä¸¤ä¸ªæ¨¡å‹æ­£å¸¸è¿è¡Œåï¼Œæ·»åŠ 2024å¹´æœ€æ–°å¯¹æ¯”æ¨¡å‹ï¼š
        # 'U-FNO': U_FNO_3D(...),           # å¤šç›¸æµå¢å¼ºç‰ˆFNO
        # 'Geo-FNO': Geo_FNO_3D(...),       # å‡ ä½•å¢å¼ºç‰ˆFNO  
        # 'Nested-FNO': Nested_FNO_3D(...), # åµŒå¥—å¼FNO
        # 'DeepONet-2024': DeepONet_2024_3D(...), # 2024æœ€æ–°DeepONetå˜ä½“
    }
    
    print(f"ğŸ“Š æ¨¡å‹é…ç½®:")
    for name, model in models.items():
        print(f"  {name}: {count_params(model):,} å‚æ•°")
    
    # FNO_RC_3Dç°åœ¨ä½¿ç”¨æ­£ç¡®çš„4ç»´è¾“å…¥æ ¼å¼ï¼Œä¸éœ€è¦ä¿®å¤get_gridæ–¹æ³•
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    print("\nğŸ‹ï¸ æ­¥éª¤4: å¼€å§‹è®­ç»ƒæ¨¡å‹")
    results = {}
    for model_name, model in models.items():
        # ç°åœ¨ä¸¤ä¸ªæ¨¡å‹éƒ½ä½¿ç”¨ç›¸åŒçš„5ç»´è¾“å…¥æ ¼å¼
        trained_model, train_losses, test_losses = train_model(
            model, model_name, train_loader, test_loader, y_normalizer, device, ntrain_actual, ntest_actual, epochs, mid_idx, last_idx
        )
        
        final_test_loss = test_losses[-1]
        results[model_name] = {
            'final_test_loss': final_test_loss,
            'train_losses': train_losses,
            'test_losses': test_losses,
            'parameters': count_params(model)
        }
        print(f"âœ… {model_name}: {final_test_loss:.6f}")
    
    # ç»“æœå¯¹æ¯”
    print(f"\nğŸ† 3Då®éªŒç»“æœ (å…³é”®æ—¶é—´ç‚¹é¢„æµ‹ - {epochs} epochs):")
    print("-" * 60)
    
    # æŒ‰æ€§èƒ½æ’åºæ˜¾ç¤º
    sorted_results = sorted(results.items(), key=lambda x: x[1]['final_test_loss'])
    
    for i, (name, result) in enumerate(sorted_results):
        rank = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰"
        print(f"{rank} {name}: {result['final_test_loss']:.6f} ({result['parameters']:,} å‚æ•°)")
    
    # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
    if len(sorted_results) >= 2:
        best_name, best_result = sorted_results[0]
        baseline_name, baseline_result = sorted_results[1]
        improvement = (baseline_result['final_test_loss'] - best_result['final_test_loss']) / baseline_result['final_test_loss'] * 100
        print(f"\nğŸ“ˆ {best_name} ç›¸å¯¹äº {baseline_name} æ”¹è¿›: {improvement:.2f}%")
    
    # å¦‚æœæœ‰åŸºçº¿ç»“æœå¯ä»¥å¯¹æ¯”
    # baseline_error = results.get('FNO3d', {}).get('final_test_loss', None)
    # if baseline_error:
    #     for name, result in results.items():
    #         if name != 'FNO3d':
    #             improvement = (baseline_error - result['final_test_loss']) / baseline_error * 100
    #             print(f"{name}: {result['final_test_loss']:.6f} (æ”¹è¿›: {improvement:+.1f}%)")
    
    # ä¿å­˜ç»“æœåˆ°Google Drive
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = '/content/drive/MyDrive/FNO_RC_Experiments/'
    os.makedirs(results_dir, exist_ok=True)
    results_file = f'{results_dir}/final_3d_comparison_{timestamp}.json'
    
    serializable_results = {}
    for name, result in results.items():
        serializable_results[name] = {
            'final_test_loss': float(result['final_test_loss']),
            'parameters': int(result['parameters']),
            'train_losses': [float(x) for x in result['train_losses']],
            'test_losses': [float(x) for x in result['test_losses']]
        }
    
    with open(results_file, 'w') as f:
        json.dump(serializable_results, f, indent=2)
    
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    print("ğŸ‰ 3Då¯¹æ¯”å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main()
