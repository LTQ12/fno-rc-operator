#!/usr/bin/env python3
"""
å®Œæ•´çš„3Då¯¹æ¯”å®éªŒ - ç¬¬ä¸€é˜¶æ®µ
åŒ…å«: æ ‡å‡†FNO3DåŸºçº¿ vs FNO-RC-3D vs B-DeepONet-3D
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import scipy.io
from scipy.io import loadmat
import h5py
import matplotlib.pyplot as plt
import json
import os
from datetime import datetime

################################################################
# æ ‡å‡†3Dé¢‘è°±å·ç§¯å±‚ - ä¸åŸå§‹è®ºæ–‡å®Œå…¨ä¸€è‡´
################################################################
class SpectralConv3d_Standard(nn.Module):
    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):
        super(SpectralConv3d_Standard, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.modes1 = modes1
        self.modes2 = modes2
        self.modes3 = modes3

        self.scale = (1 / (in_channels * out_channels))
        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))
        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))
        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))
        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))

    def compl_mul3d(self, input, weights):
        return torch.einsum("bixyz,ioxyz->boxyz", input, weights)

    def forward(self, x):
        batchsize = x.shape[0]
        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1])

        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)
        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \
            self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)
        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \
            self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)
        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \
            self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)
        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \
            self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)

        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))
        return x

################################################################
# æ ‡å‡†FNO3Dæ¨¡å‹ - ä¸åŸå§‹è®ºæ–‡å®Œå…¨ä¸€è‡´
################################################################
class FNO3d_Standard(nn.Module):
    def __init__(self, modes1, modes2, modes3, width):
        super(FNO3d_Standard, self).__init__()
        self.modes1 = modes1
        self.modes2 = modes2
        self.modes3 = modes3
        self.width = width
        self.padding = 6
        self.fc0 = nn.Linear(13, self.width)  # 10ä¸ªæ—¶é—´æ­¥ + 3ä¸ªåæ ‡

        self.conv0 = SpectralConv3d_Standard(self.width, self.width, self.modes1, self.modes2, self.modes3)
        self.conv1 = SpectralConv3d_Standard(self.width, self.width, self.modes1, self.modes2, self.modes3)
        self.conv2 = SpectralConv3d_Standard(self.width, self.width, self.modes1, self.modes2, self.modes3)
        self.conv3 = SpectralConv3d_Standard(self.width, self.width, self.modes1, self.modes2, self.modes3)
        self.w0 = nn.Conv3d(self.width, self.width, 1)
        self.w1 = nn.Conv3d(self.width, self.width, 1)
        self.w2 = nn.Conv3d(self.width, self.width, 1)
        self.w3 = nn.Conv3d(self.width, self.width, 1)

        self.fc1 = nn.Linear(self.width, 128)
        self.fc2 = nn.Linear(128, 1)

    def forward(self, x):
        grid = self.get_grid(x.shape, x.device)
        x = torch.cat((x, grid), dim=-1)
        x = self.fc0(x)
        x = x.permute(0, 4, 1, 2, 3)
        x = F.pad(x, [0, self.padding])

        x1 = self.conv0(x)
        x2 = self.w0(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv1(x)
        x2 = self.w1(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv2(x)
        x2 = self.w2(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv3(x)
        x2 = self.w3(x)
        x = x1 + x2

        x = x[..., :-self.padding]
        x = x.permute(0, 2, 3, 4, 1)
        x = self.fc1(x)
        x = F.gelu(x)
        x = self.fc2(x)
        return x

    def get_grid(self, shape, device):
        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]
        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])
        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])
        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])
        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)

################################################################
# CFTå·¥å…·å‡½æ•°
################################################################
def vectorized_batched_cft(u, t_coords, f_points, L_segments, M_cheb):
    """å‘é‡åŒ–çš„æ‰¹é‡CFTè®¡ç®—"""
    device = u.device
    dtype = u.dtype
    
    B, C, N = u.shape
    K = len(f_points)
    
    # åˆ†æ®µå¤„ç†
    segment_size = N // L_segments
    cft_results = torch.zeros(B, C, K, dtype=torch.complex64, device=device)
    
    for seg_idx in range(L_segments):
        start_idx = seg_idx * segment_size
        end_idx = min((seg_idx + 1) * segment_size, N)
        
        if start_idx >= end_idx:
            continue
            
        # å½“å‰æ®µçš„æ•°æ®å’Œåæ ‡
        u_seg = u[:, :, start_idx:end_idx]
        t_seg = t_coords[start_idx:end_idx]
        
        # æ˜ å°„åˆ°[-1, 1]
        t_min, t_max = t_seg.min(), t_seg.max()
        if t_max > t_min:
            t_mapped = 2 * (t_seg - t_min) / (t_max - t_min) - 1
        else:
            t_mapped = torch.zeros_like(t_seg)
        
        # Chebyshevå¤šé¡¹å¼
        T_cheb = torch.ones(len(t_mapped), M_cheb, device=device)
        if M_cheb > 1:
            T_cheb[:, 1] = t_mapped
        for m in range(2, M_cheb):
            T_cheb[:, m] = 2 * t_mapped * T_cheb[:, m-1] - T_cheb[:, m-2]
        
        # CFTè®¡ç®—
        for k_idx, f_k in enumerate(f_points):
            phase = torch.exp(-2j * np.pi * f_k * t_seg)
            integrand = u_seg * phase.unsqueeze(0).unsqueeze(0)
            
            # ä½¿ç”¨Chebyshevç§¯åˆ†
            weights = torch.ones(len(t_seg), device=device) * (t_max - t_min) / len(t_seg)
            cft_results[:, :, k_idx] += torch.sum(integrand * weights.unsqueeze(0).unsqueeze(0), dim=2)
    
    return cft_results

def cft3d(x, modes1, modes2, modes3, L_segments=8, M_cheb=8):
    """3D CFTå˜æ¢"""
    B, C, H, W, T = x.shape
    device = x.device
    
    # 1. æ—¶é—´ç»´åº¦FFT
    x_ft = torch.fft.rfft(x, dim=-1)
    x_ft_filtered = x_ft[..., :modes3]
    
    # 2. CFTå¤„ç†
    x_reshaped = x_ft_filtered.permute(0, 1, 4, 2, 3).reshape(B, C * modes3, H, W)
    
    # Widthæ–¹å‘CFT
    t_coords_w = torch.linspace(0, 1, W, device=device, dtype=x.dtype)
    f_points_w = torch.fft.rfftfreq(W, d=1.0/W)[:modes2].to(device)
    cft_w_input = x_reshaped.permute(0, 2, 1, 3).reshape(B * H, C * modes3, W)
    
    cft_w_real = vectorized_batched_cft(cft_w_input.real, t_coords_w, f_points_w, L_segments, M_cheb)
    cft_w_imag = vectorized_batched_cft(cft_w_input.imag, t_coords_w, f_points_w, L_segments, M_cheb)
    cft_w_complex = cft_w_real + 1j * cft_w_imag
    cft_w_complex = cft_w_complex.view(B, H, C * modes3, modes2).permute(0, 2, 1, 3)

    # Heightæ–¹å‘CFT
    t_coords_h = torch.linspace(0, 1, H, device=device, dtype=x.dtype)
    f_points_h = torch.fft.fftfreq(H, d=1.0/H).to(device)
    h_indices = torch.cat((torch.arange(0, modes1//2), torch.arange(H-(modes1-modes1//2), H))).to(device)
    f_points_h_selected = f_points_h[h_indices]
    cft_h_input = cft_w_complex.permute(0, 3, 1, 2).reshape(B * modes2, C * modes3, H)

    cft_h_real = vectorized_batched_cft(cft_h_input.real, t_coords_h, f_points_h_selected, L_segments, M_cheb)
    cft_h_imag = vectorized_batched_cft(cft_h_input.imag, t_coords_h, f_points_h_selected, L_segments, M_cheb)
    cft_hwt_complex = cft_h_real + 1j * cft_h_imag
    
    cft_hwt_complex = cft_hwt_complex.view(B, modes2, C, modes3, modes1).permute(0, 2, 4, 1, 3)
    return cft_hwt_complex

################################################################
# FNO-RC 3Dæ¨¡å‹
################################################################
class SpectralConv3d_RC(nn.Module):
    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):
        super(SpectralConv3d_RC, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.modes1 = modes1
        self.modes2 = modes2
        self.modes3 = modes3

        self.scale = (1 / (in_channels * out_channels))
        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))
        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))
        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))
        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))

        # CFTæ®‹å·®ä¿®æ­£è·¯å¾„
        self.cft_modes1 = modes1 // 2
        self.cft_modes2 = modes2 // 2
        self.cft_modes3 = modes3 // 2
        cft_flat_dim = self.in_channels * self.cft_modes1 * self.cft_modes2 * self.cft_modes3 * 2

        self.correction_generator = nn.Sequential(
            nn.Linear(cft_flat_dim, (self.in_channels + self.out_channels) * 2),
            nn.GELU(),
            nn.Linear((self.in_channels + self.out_channels) * 2, self.out_channels)
        )
        nn.init.zeros_(self.correction_generator[-1].weight)
        nn.init.zeros_(self.correction_generator[-1].bias)

    def forward(self, x):
        B, C, H, W, T = x.shape

        # æ ‡å‡†FNOè·¯å¾„
        x_ft = torch.fft.rfftn(x, dim=[-3, -2, -1])
        out_ft = torch.zeros(B, self.out_channels, H, W, T//2 + 1, dtype=torch.cfloat, device=x.device)
        
        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = torch.einsum("bixyz,ioxyz->boxyz", x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)
        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = torch.einsum("bixyz,ioxyz->boxyz", x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)
        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = torch.einsum("bixyz,ioxyz->boxyz", x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)
        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = torch.einsum("bixyz,ioxyz->boxyz", x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)
        
        x_fno = torch.fft.irfftn(out_ft, s=(H, W, T))

        # CFTæ®‹å·®ä¿®æ­£è·¯å¾„
        try:
            x_cft = cft3d(x, self.cft_modes1, self.cft_modes2, self.cft_modes3, L_segments=8, M_cheb=8)
            x_cft_real = torch.cat([x_cft.real, x_cft.imag], dim=-1)
            x_cft_flat = x_cft_real.reshape(B, H, W, T, -1)
            correction = self.correction_generator(x_cft_flat)
            return x_fno + correction
        except:
            return x_fno

class FNO_RC_3D(nn.Module):
    def __init__(self, modes1, modes2, modes3, width):
        super(FNO_RC_3D, self).__init__()
        self.modes1 = modes1
        self.modes2 = modes2
        self.modes3 = modes3
        self.width = width
        self.padding = 6
        self.fc0 = nn.Linear(13, self.width)

        self.conv0 = SpectralConv3d_RC(self.width, self.width, self.modes1, self.modes2, self.modes3)
        self.conv1 = SpectralConv3d_RC(self.width, self.width, self.modes1, self.modes2, self.modes3)
        self.conv2 = SpectralConv3d_RC(self.width, self.width, self.modes1, self.modes2, self.modes3)
        self.conv3 = SpectralConv3d_RC(self.width, self.width, self.modes1, self.modes2, self.modes3)
        self.w0 = nn.Conv3d(self.width, self.width, 1)
        self.w1 = nn.Conv3d(self.width, self.width, 1)
        self.w2 = nn.Conv3d(self.width, self.width, 1)
        self.w3 = nn.Conv3d(self.width, self.width, 1)

        self.fc1 = nn.Linear(self.width, 128)
        self.fc2 = nn.Linear(128, 1)

    def forward(self, x):
        grid = self.get_grid(x.shape, x.device)
        x = torch.cat((x, grid), dim=-1)
        x = self.fc0(x)
        x = x.permute(0, 4, 1, 2, 3)
        x = F.pad(x, [0, self.padding])

        x1 = self.conv0(x)
        x2 = self.w0(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv1(x)
        x2 = self.w1(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv2(x)
        x2 = self.w2(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv3(x)
        x2 = self.w3(x)
        x = x1 + x2

        x = x[..., :-self.padding]
        x = x.permute(0, 2, 3, 4, 1)
        x = self.fc1(x)
        x = F.gelu(x)
        x = self.fc2(x)
        return x

    def get_grid(self, shape, device):
        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]
        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])
        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])
        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])
        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)

################################################################
# B-DeepONet 3Dæ¨¡å‹
################################################################
class BDeepONet3D(nn.Module):
    def __init__(self, modes1, modes2, modes3, width):
        super(BDeepONet3D, self).__init__()
        self.modes1 = modes1
        self.modes2 = modes2
        self.modes3 = modes3
        self.width = width
        
        # Branchç½‘ç»œ
        self.branch_net = nn.Sequential(
            nn.Linear(13, width),
            nn.GELU(),
            nn.Linear(width, width),
            nn.GELU(),
            nn.Linear(width, width),
            nn.GELU(),
            nn.Linear(width, width)
        )
        
        # Trunkç½‘ç»œ
        self.trunk_net = nn.Sequential(
            nn.Linear(3, width),
            nn.GELU(),
            nn.Linear(width, width),
            nn.GELU(),
            nn.Linear(width, width),
            nn.GELU(),
            nn.Linear(width, width)
        )
        
        self.output_layer = nn.Linear(width, 1)

    def forward(self, x):
        B, H, W, T, C = x.shape
        
        # è·å–ç½‘æ ¼åæ ‡
        grid = self.get_grid(x.shape, x.device)
        
        # Branchç½‘ç»œå¤„ç†è¾“å…¥
        x_with_grid = torch.cat((x, grid), dim=-1)
        branch_out = self.branch_net(x_with_grid)  # [B, H, W, T, width]
        
        # Trunkç½‘ç»œå¤„ç†åæ ‡
        trunk_out = self.trunk_net(grid)  # [B, H, W, T, width]
        
        # ç»„åˆ
        combined = branch_out * trunk_out  # [B, H, W, T, width]
        output = self.output_layer(combined)  # [B, H, W, T, 1]
        
        return output

    def get_grid(self, shape, device):
        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]
        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])
        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])
        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)
        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])
        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)

################################################################
# æ•°æ®é¢„å¤„ç†
################################################################
def preprocess_3d_comparison(data_path, T_in=10, T_out=20, ntrain=40, ntest=10):
    """3Då¯¹æ¯”å®éªŒæ•°æ®é¢„å¤„ç† - æ”¯æŒMatlab v7.3æ ¼å¼"""
    try:
        # é¦–å…ˆå°è¯•scipy.io.loadmat
        try:
            data = loadmat(data_path)
            u_field = data['u']
            print(f"âœ… ä½¿ç”¨scipy.ioåŠ è½½æˆåŠŸ")
        except:
            # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨h5pyåŠ è½½Matlab v7.3æ–‡ä»¶
            print("ğŸ“ æ£€æµ‹åˆ°Matlab v7.3æ ¼å¼ï¼Œä½¿ç”¨h5pyåŠ è½½...")
            with h5py.File(data_path, 'r') as f:
                # æŸ¥çœ‹æ–‡ä»¶ä¸­çš„é”®
                keys = list(f.keys())
                print(f"æ–‡ä»¶ä¸­çš„é”®: {keys}")
                
                # å¯»æ‰¾æ•°æ®å­—æ®µ
                if 'u' in f:
                    u_field = np.array(f['u'])
                elif 'data' in f:
                    u_field = np.array(f['data'])
                else:
                    # å°è¯•ç¬¬ä¸€ä¸ªéå…ƒæ•°æ®é”®
                    data_key = [k for k in keys if not k.startswith('#')][0]
                    u_field = np.array(f[data_key])
                    print(f"ä½¿ç”¨é”®: {data_key}")
                
                # h5pyåŠ è½½çš„æ•°æ®å¯èƒ½éœ€è¦è½¬ç½®
                if u_field.ndim == 4:
                    # é€šå¸¸h5pyåŠ è½½çš„ç»´åº¦é¡ºåºæ˜¯ [T, W, H, N]ï¼Œéœ€è¦è½¬ç½®ä¸º [N, H, W, T]
                    u_field = u_field.transpose(3, 2, 1, 0)
                    print(f"æ•°æ®å·²è½¬ç½®ä¸ºæ ‡å‡†æ ¼å¼")
            
            print(f"âœ… ä½¿ç”¨h5pyåŠ è½½æˆåŠŸ")
        
        print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {u_field.shape}")
        
        N, H, W, T_total = u_field.shape
        if T_total < T_in + T_out:
            print(f"æ—¶é—´æ­¥ä¸è¶³: éœ€è¦{T_in + T_out}, å®é™…{T_total}")
            return None, None, None, None
        
        T_window = T_in + T_out
        train_data = u_field[:ntrain, ..., :T_window]
        test_data = u_field[-ntest:, ..., :T_window]
        
        def create_input(data):
            N, H, W, T_win = data.shape
            initial_steps = data[..., :T_in]  # [N, H, W, T_in]
            # è½¬æ¢ä¸ºtorch tensorä»¥ä½¿ç”¨expand
            initial_steps = torch.tensor(initial_steps, dtype=torch.float32)
            input_field = torch.zeros(N, H, W, T_win, T_in)
            for i in range(T_in):
                # ä½¿ç”¨torch tensorçš„expandæ–¹æ³•
                step_expanded = initial_steps[..., i:i+1].expand(-1, -1, -1, T_win)
                input_field[..., i] = step_expanded.squeeze(-1)
            return input_field
        
        train_a = create_input(train_data)
        test_a = create_input(test_data)
        train_u = torch.tensor(train_data[..., T_in:], dtype=torch.float32).unsqueeze(-1)
        test_u = torch.tensor(test_data[..., T_in:], dtype=torch.float32).unsqueeze(-1)
        
        train_a = train_a.float()
        test_a = test_a.float()
        
        print(f"é¢„å¤„ç†å®Œæˆ:")
        print(f"è®­ç»ƒè¾“å…¥: {train_a.shape}, è®­ç»ƒè¾“å‡º: {train_u.shape}")
        print(f"æµ‹è¯•è¾“å…¥: {test_a.shape}, æµ‹è¯•è¾“å‡º: {test_u.shape}")
        
        return train_a, train_u, test_a, test_u
        
    except Exception as e:
        print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None, None, None, None

################################################################
# æŸå¤±å‡½æ•°
################################################################
class LpLoss(object):
    def __init__(self, d=2, p=2, size_average=True, reduction=True):
        super(LpLoss, self).__init__()
        self.d = d
        self.p = p
        self.reduction = reduction
        self.size_average = size_average

    def abs(self, x, y):
        num_examples = x.size()[0]
        diff_norms = torch.norm(x.reshape(num_examples, -1) - y.reshape(num_examples, -1), self.p, 1)
        y_norms = torch.norm(y.reshape(num_examples, -1), self.p, 1)
        
        if self.reduction:
            if self.size_average:
                return torch.mean(diff_norms / y_norms)
            else:
                return torch.sum(diff_norms / y_norms)
        return diff_norms / y_norms

    def rel(self, x, y):
        return self.abs(x, y)

################################################################
# è®­ç»ƒå‡½æ•°
################################################################
def train_model(model, model_name, train_loader, test_loader, device, epochs=100):
    """ç»Ÿä¸€çš„æ¨¡å‹è®­ç»ƒå‡½æ•°"""
    model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)
    myloss = LpLoss(size_average=False)
    
    train_losses = []
    test_losses = []
    
    print(f"ğŸ”§ å¼€å§‹è®­ç»ƒ {model_name}...")
    print(f"ğŸ“Š å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            
            optimizer.zero_grad()
            out = model(x)
            
            if out.shape != y.shape:
                print(f"âŒ å½¢çŠ¶ä¸åŒ¹é…: è¾“å‡º{out.shape} vs æ ‡ç­¾{y.shape}")
                return None, None, None
                
            loss = myloss.rel(out, y)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        model.eval()
        test_loss = 0
        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(device), y.to(device)
                out = model(x)
                test_loss += myloss.rel(out, y).item()
        
        scheduler.step()
        
        train_loss = train_loss / len(train_loader)
        test_loss = test_loss / len(test_loader)
        
        train_losses.append(train_loss)
        test_losses.append(test_loss)
        
        if epoch % 25 == 0:
            print(f'  Epoch {epoch}: Train {train_loss:.6f}, Test {test_loss:.6f}')
    
    return model, train_losses, test_losses

################################################################
# ä¸»å‡½æ•°
################################################################
def main():
    print("ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: cuda" if torch.cuda.is_available() else "ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: cpu")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    if torch.cuda.is_available():
        print(f"ğŸ“± GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    print("ğŸš€ å¼€å§‹3Då¯¹æ¯”å®éªŒ")
    
    # æ•°æ®åŠ è½½
    data_path = '/content/drive/MyDrive/ns_V1e-4_N10000_T30.mat'
    train_a, train_u, test_a, test_u = preprocess_3d_comparison(data_path)
    
    if train_a is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        return
    
    # æ•°æ®åŠ è½½å™¨
    train_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(train_a, train_u), 
        batch_size=4, shuffle=True
    )
    test_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(test_a, test_u), 
        batch_size=4, shuffle=False
    )
    
    # æ¨¡å‹å®šä¹‰
    models = {
        'FNO3D_Standard': FNO3d_Standard(modes1=8, modes2=8, modes3=8, width=20),
        'FNO_RC_3D': FNO_RC_3D(modes1=8, modes2=8, modes3=8, width=20),
        'B_DeepONet_3D': BDeepONet3D(modes1=8, modes2=8, modes3=8, width=20)
    }
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    results = {}
    for model_name, model in models.items():
        trained_model, train_losses, test_losses = train_model(
            model, model_name, train_loader, test_loader, device, epochs=100
        )
        
        if trained_model is not None:
            final_test_loss = test_losses[-1]
            results[model_name] = {
                'final_test_loss': final_test_loss,
                'train_losses': train_losses,
                'test_losses': test_losses,
                'parameters': sum(p.numel() for p in model.parameters())
            }
            print(f"âœ… {model_name}: {final_test_loss:.6f}")
        else:
            print(f"âŒ {model_name}: è®­ç»ƒå¤±è´¥")
    
    # ç»“æœå¯¹æ¯”
    print(f"\nğŸ† 3Då¯¹æ¯”å®éªŒç»“æœ:")
    print("-" * 60)
    
    if 'FNO3D_Standard' in results:
        baseline_error = results['FNO3D_Standard']['final_test_loss']
        print(f"FNO3D_Standard: {baseline_error:.6f} (åŸºçº¿)")
        
        for name, result in results.items():
            if name != 'FNO3D_Standard':
                improvement = (baseline_error - result['final_test_loss']) / baseline_error * 100
                print(f"{name}: {result['final_test_loss']:.6f} (æ”¹è¿›: {improvement:+.1f}%)")
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f'/content/drive/MyDrive/3d_comparison_results_{timestamp}.json'
    
    # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
    serializable_results = {}
    for name, result in results.items():
        serializable_results[name] = {
            'final_test_loss': float(result['final_test_loss']),
            'parameters': int(result['parameters']),
            'train_losses': [float(x) for x in result['train_losses']],
            'test_losses': [float(x) for x in result['test_losses']]
        }
    
    with open(results_file, 'w') as f:
        json.dump(serializable_results, f, indent=2)
    
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    print("ğŸ‰ 3Då¯¹æ¯”å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main()
