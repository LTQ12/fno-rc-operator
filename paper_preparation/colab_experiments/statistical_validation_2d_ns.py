"""
FNO-RC 2D Navier-Stokes ç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯å®éªŒ
ä¸“ä¸ºGoogle Colabç¯å¢ƒè®¾è®¡ï¼Œèšç„¦æœ€æ˜¾è‘—çš„æ”¹è¿›ç»“æœ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import json
import os
import time
from datetime import datetime
import pickle
import warnings
warnings.filterwarnings('ignore')

# ================================
# Colabç¯å¢ƒè®¾ç½®
# ================================

def setup_colab_environment():
    """è®¾ç½®Colabç¯å¢ƒ"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    base_path = "/content/drive/MyDrive/FNO_RC_Experiments"
    os.makedirs(f"{base_path}/results/statistical_validation_2d", exist_ok=True)
    os.makedirs(f"{base_path}/models/2d_ns", exist_ok=True)
    os.makedirs(f"{base_path}/logs", exist_ok=True)
    
    return device, base_path

# ================================
# 2D FNOæ¨¡å‹å®šä¹‰
# ================================

class SpectralConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, modes1, modes2):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.modes1 = modes1
        self.modes2 = modes2

        self.scale = (1 / (in_channels * out_channels))
        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))
        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))

    def forward(self, x):
        batchsize = x.shape[0]
        # FFT
        x_ft = torch.fft.rfft2(x)

        # Multiply relevant Fourier modes
        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)
        out_ft[:, :, :self.modes1, :self.modes2] = \
            torch.einsum("bixy,ioxy->boxy", x_ft[:, :, :self.modes1, :self.modes2], self.weights1)
        out_ft[:, :, -self.modes1:, :self.modes2] = \
            torch.einsum("bixy,ioxy->boxy", x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)

        # IFFT
        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))
        return x

class CFTLayer2d(nn.Module):
    """2D CFTå±‚å®ç°"""
    def __init__(self, in_channels, out_channels, modes1, modes2, segments=4):
        super().__init__()
        self.modes1 = modes1
        self.modes2 = modes2
        self.segments = segments
        self.in_channels = in_channels
        self.out_channels = out_channels
        
        # Chebyshevæƒé‡
        self.chebyshev_weights = nn.Parameter(
            torch.randn(segments, segments, modes1, modes2, in_channels, out_channels) * 0.02
        )
        
    def chebyshev_transform_2d(self, x, n_modes1, n_modes2):
        """2D Chebyshevå˜æ¢"""
        batch_size, channels, h, w = x.shape
        
        # å½’ä¸€åŒ–åˆ°[-1,1] - ä¿®å¤reshapeé—®é¢˜
        x_flat = x.reshape(batch_size, channels, -1)  # ä½¿ç”¨reshapeè€Œä¸æ˜¯view
        x_min = x_flat.min(dim=-1, keepdim=True)[0].unsqueeze(-1)
        x_max = x_flat.max(dim=-1, keepdim=True)[0].unsqueeze(-1)
        x_norm = 2 * (x - x_min.reshape(batch_size, channels, 1, 1)) / (x_max.reshape(batch_size, channels, 1, 1) - x_min.reshape(batch_size, channels, 1, 1) + 1e-8) - 1
        
        # ç®€åŒ–çš„2D Chebyshevå±•å¼€
        coeffs = []
        max_modes = min(n_modes1, n_modes2, 6)  # è¿›ä¸€æ­¥é™åˆ¶ä»¥é¿å…å†…å­˜é—®é¢˜
        
        for i in range(max_modes):
            for j in range(max_modes):
                if i == 0 and j == 0:
                    T_ij = torch.ones_like(x_norm)
                elif i == 0:
                    T_ij = torch.cos(j * torch.acos(torch.clamp(x_norm, -1+1e-6, 1-1e-6)))
                elif j == 0:
                    T_ij = torch.cos(i * torch.acos(torch.clamp(x_norm, -1+1e-6, 1-1e-6)))
                else:
                    T_ij = torch.cos(i * torch.acos(torch.clamp(x_norm, -1+1e-6, 1-1e-6))) * \
                           torch.cos(j * torch.acos(torch.clamp(x_norm, -1+1e-6, 1-1e-6)))
                
                coeff = torch.mean(x_norm * T_ij, dim=(-2, -1), keepdim=True)
                coeffs.append(coeff.squeeze(-1).squeeze(-1))  # ç§»é™¤ç©ºç»´åº¦
        
        # å®‰å…¨åœ°æ‹¼æ¥ç³»æ•°
        if coeffs:
            return torch.stack(coeffs, dim=-1)  # (batch, channels, num_coeffs)
        else:
            return torch.zeros(batch_size, channels, 1, device=x.device)
    
    def forward(self, x):
        batch_size, channels, h, w = x.shape
        
        # åˆ†æ®µå¤„ç†
        h_seg = h // self.segments
        w_seg = w // self.segments
        results = []
        
        for i in range(self.segments):
            for j in range(self.segments):
                h_start, h_end = i * h_seg, (i + 1) * h_seg if i < self.segments - 1 else h
                w_start, w_end = j * w_seg, (j + 1) * w_seg if j < self.segments - 1 else w
                
                x_segment = x[:, :, h_start:h_end, w_start:w_end]
                
                # Chebyshevå˜æ¢
                coeffs = self.chebyshev_transform_2d(x_segment, self.modes1, self.modes2)
                
                # åº”ç”¨å­¦ä¹ æƒé‡ - ä¿®å¤ç»´åº¦åŒ¹é…
                num_coeffs = coeffs.shape[-1]
                max_weight_coeffs = self.chebyshev_weights.shape[2] * self.chebyshev_weights.shape[3]
                
                if num_coeffs <= max_weight_coeffs:
                    # ä½¿ç”¨å¯ç”¨çš„æƒé‡
                    weight_flat = self.chebyshev_weights[i, j].reshape(-1, self.in_channels, self.out_channels)[:num_coeffs]
                    coeffs_filtered = torch.einsum('bci,ico->bco', coeffs, weight_flat)
                else:
                    # æˆªæ–­ç³»æ•°ä»¥åŒ¹é…æƒé‡ç»´åº¦
                    coeffs_truncated = coeffs[:, :, :max_weight_coeffs]
                    weight_flat = self.chebyshev_weights[i, j].reshape(-1, self.in_channels, self.out_channels)
                    coeffs_filtered = torch.einsum('bci,ico->bco', coeffs_truncated, weight_flat)
                
                # é‡æ„ä¿¡å· - ç®€åŒ–å¤„ç†
                if coeffs_filtered.shape[-1] > 0:
                    signal = torch.tanh(coeffs_filtered.mean(dim=-1, keepdim=True))  # (batch, channels, 1)
                    reconstructed = signal.unsqueeze(-1).expand(-1, -1, h_end-h_start, w_end-w_start)
                else:
                    reconstructed = torch.zeros(batch_size, self.out_channels, h_end-h_start, w_end-w_start, device=x.device)
                
                results.append(reconstructed)
        
        # é‡æ–°ç»„åˆ
        row_results = []
        for i in range(self.segments):
            row = torch.cat(results[i*self.segments:(i+1)*self.segments], dim=-1)
            row_results.append(row)
        
        return torch.cat(row_results, dim=-2)

class FNOLayer2d(nn.Module):
    def __init__(self, modes1, modes2, width):
        super().__init__()
        self.conv = SpectralConv2d(width, width, modes1, modes2)
        self.w = nn.Conv2d(width, width, 1)
        
    def forward(self, x):
        return self.conv(x) + self.w(x)

class StandardFNO2d(nn.Module):
    """æ ‡å‡†2D FNOæ¨¡å‹"""
    def __init__(self, modes1=12, modes2=12, width=32, num_layers=4):
        super().__init__()
        self.modes1 = modes1
        self.modes2 = modes2
        self.width = width
        self.num_layers = num_layers
        
        self.fc0 = nn.Linear(3, self.width)  # (a(x,y), x, y) -> width
        self.layers = nn.ModuleList([FNOLayer2d(modes1, modes2, width) for _ in range(num_layers)])
        self.fc1 = nn.Linear(width, 128)
        self.fc2 = nn.Linear(128, 1)
        self.activation = nn.GELU()
        
    def forward(self, x):
        # x shape: (batch, h, w, 3)
        x = self.fc0(x)  # (batch, h, w, width)
        x = x.permute(0, 3, 1, 2)  # (batch, width, h, w)
        
        for layer in self.layers:
            x = self.activation(layer(x))
            
        x = x.permute(0, 2, 3, 1)  # (batch, h, w, width)
        x = self.fc1(x)
        x = self.activation(x)
        x = self.fc2(x)  # (batch, h, w, 1)
        return x

class FNORCF2d(nn.Module):
    """2D FNO-RCæ¨¡å‹"""
    def __init__(self, modes1=12, modes2=12, width=32, num_layers=4, cft_segments=4, cft_modes1=8, cft_modes2=8):
        super().__init__()
        self.modes1 = modes1
        self.modes2 = modes2
        self.width = width
        self.num_layers = num_layers
        
        # è¾“å…¥åµŒå…¥
        self.fc0 = nn.Linear(3, self.width)
        
        # FNOä¸»è·¯å¾„
        self.fno_layers = nn.ModuleList([FNOLayer2d(modes1, modes2, width) for _ in range(num_layers)])
        
        # CFTæ®‹å·®è·¯å¾„
        self.cft_layers = nn.ModuleList([CFTLayer2d(width, width, cft_modes1, cft_modes2, cft_segments) for _ in range(num_layers)])
        
        # é—¨æ§æœºåˆ¶
        self.gate_layers = nn.ModuleList([nn.Conv2d(2*width, width, 1) for _ in range(num_layers)])
        
        # è¾“å‡ºå±‚
        self.fc1 = nn.Linear(width, 128)
        self.fc2 = nn.Linear(128, 1)
        self.activation = nn.GELU()
        
    def forward(self, x):
        # x shape: (batch, h, w, 3)
        x = self.fc0(x)  # (batch, h, w, width)
        x = x.permute(0, 3, 1, 2)  # (batch, width, h, w)
        
        for i in range(self.num_layers):
            # FNOè·¯å¾„
            x_fno = self.fno_layers[i](x)
            x_fno = self.activation(x_fno)
            
            # CFTè·¯å¾„
            x_cft = self.cft_layers[i](x)
            
            # é—¨æ§èåˆ
            x_concat = torch.cat([x_fno, x_cft], dim=1)  # (batch, 2*width, h, w)
            gate = torch.sigmoid(self.gate_layers[i](x_concat))  # (batch, width, h, w)
            
            # æ®‹å·®è¿æ¥
            x = x_fno + gate * x_cft
        
        # è¾“å‡ºå±‚
        x = x.permute(0, 2, 3, 1)  # (batch, h, w, width)
        x = self.fc1(x)
        x = self.activation(x)
        x = self.fc2(x)  # (batch, h, w, 1)
        return x

# ================================
# æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
# ================================

def load_navier_stokes_data():
    """åŠ è½½2D Navier-Stokesæ•°æ®"""
    print("Loading 2D Navier-Stokes data...")
    
    data_path = "/content/drive/MyDrive/FNO_RC_Experiments/data"
    
    try:
        # å°è¯•åŠ è½½ç°æœ‰æ•°æ®
        data_file = f"{data_path}/ns_2d_data.pt"
        data = torch.load(data_file)
        train_a = data['train_a']
        train_u = data['train_u']
        test_a = data['test_a']
        test_u = data['test_u']
        print(f"Loaded existing data: train {train_a.shape}, test {test_a.shape}")
        
    except:
        print("Generating synthetic 2D Navier-Stokes data...")
        # ç”Ÿæˆåˆæˆæ•°æ®
        resolution = 64  # ä½¿ç”¨64x64ä»¥èŠ‚çœè®¡ç®—
        n_train, n_test = 600, 100
        
        np.random.seed(42)
        torch.manual_seed(42)
        
        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        train_a = []
        train_u = []
        
        for i in range(n_train):
            # ç”Ÿæˆæ¶¡æ—‹åˆå§‹æ¡ä»¶
            x = torch.linspace(0, 1, resolution)
            y = torch.linspace(0, 1, resolution)
            X, Y = torch.meshgrid(x, y, indexing='ij')
            
            # å¤šæ¶¡æ—‹ç»“æ„
            vorticity = (torch.sin(2*np.pi*X) * torch.cos(2*np.pi*Y) + 
                        0.5 * torch.sin(4*np.pi*X) * torch.cos(4*np.pi*Y) +
                        torch.randn(resolution, resolution) * 0.1)
            
            # ç®€åŒ–çš„æ¼”åŒ–ï¼ˆå®é™…åº”è¯¥ç”¨NSæ±‚è§£å™¨ï¼‰
            evolved = vorticity * 0.8 + 0.1 * torch.sin(6*np.pi*X) * torch.cos(6*np.pi*Y) + \
                     torch.randn(resolution, resolution) * 0.05
            
            train_a.append(vorticity)
            train_u.append(evolved)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_a = []
        test_u = []
        
        for i in range(n_test):
            x = torch.linspace(0, 1, resolution)
            y = torch.linspace(0, 1, resolution)
            X, Y = torch.meshgrid(x, y, indexing='ij')
            
            vorticity = (torch.cos(3*np.pi*X) * torch.sin(3*np.pi*Y) + 
                        0.3 * torch.cos(6*np.pi*X) * torch.sin(6*np.pi*Y) +
                        torch.randn(resolution, resolution) * 0.1)
            
            evolved = vorticity * 0.8 + 0.1 * torch.cos(8*np.pi*X) * torch.sin(8*np.pi*Y) + \
                     torch.randn(resolution, resolution) * 0.05
            
            test_a.append(vorticity)
            test_u.append(evolved)
        
        train_a = torch.stack(train_a)
        train_u = torch.stack(train_u)
        test_a = torch.stack(test_a)
        test_u = torch.stack(test_u)
        
        # ä¿å­˜æ•°æ®
        os.makedirs(data_path, exist_ok=True)
        torch.save({
            'train_a': train_a,
            'train_u': train_u,
            'test_a': test_a,
            'test_u': test_u
        }, f"{data_path}/ns_2d_data.pt")
        
        print(f"Generated and saved data: train {train_a.shape}, test {test_a.shape}")
    
    return train_a, train_u, test_a, test_u

def prepare_data_loaders_2d(train_a, train_u, test_a, test_u, batch_size=10):
    """å‡†å¤‡2Dæ•°æ®åŠ è½½å™¨"""
    resolution = train_a.shape[-1]
    
    # åˆ›å»ºåæ ‡ç½‘æ ¼
    x = torch.linspace(0, 1, resolution)
    y = torch.linspace(0, 1, resolution)
    X, Y = torch.meshgrid(x, y, indexing='ij')
    grid = torch.stack([X, Y], dim=-1).unsqueeze(0)  # (1, h, w, 2)
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    train_input = torch.cat([
        train_a.unsqueeze(-1),  # (batch, h, w, 1)
        grid.repeat(train_a.shape[0], 1, 1, 1)  # (batch, h, w, 2)
    ], dim=-1)  # (batch, h, w, 3)
    train_target = train_u.unsqueeze(-1)  # (batch, h, w, 1)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_input = torch.cat([
        test_a.unsqueeze(-1),
        grid.repeat(test_a.shape[0], 1, 1, 1)
    ], dim=-1)
    test_target = test_u.unsqueeze(-1)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader, TensorDataset
    train_dataset = TensorDataset(train_input, train_target)
    test_dataset = TensorDataset(test_input, test_target)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    return train_loader, test_loader

# ================================
# è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°
# ================================

class LpLoss(object):
    def __init__(self, d=2, p=2, size_average=True, reduction=True):
        super().__init__()
        self.d = d
        self.p = p
        self.reduction = reduction
        self.size_average = size_average

    def __call__(self, x, y):
        num_examples = x.size()[0]
        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)
        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)
        
        if self.reduction:
            if self.size_average:
                return torch.mean(diff_norms/y_norms)
            else:
                return torch.sum(diff_norms/y_norms)
        
        return diff_norms/y_norms

def train_model_2d(model, train_loader, test_loader, device, epochs=300, lr=0.001, save_path=None):
    """è®­ç»ƒ2Dæ¨¡å‹"""
    model = model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    loss_fn = LpLoss(size_average=True)
    
    train_losses = []
    test_losses = []
    best_test_loss = float('inf')
    
    print(f"Starting training for {epochs} epochs...")
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = loss_fn(output, target)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        # æµ‹è¯•é˜¶æ®µ
        model.eval()
        test_loss = 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                test_loss += loss_fn(output, target).item()
        
        train_loss /= len(train_loader)
        test_loss /= len(test_loader)
        
        train_losses.append(train_loss)
        test_losses.append(test_loss)
        
        scheduler.step()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if test_loss < best_test_loss and save_path:
            best_test_loss = test_loss
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'test_loss': test_loss,
                'epoch': epoch
            }, save_path)
        
        if epoch % 25 == 0:
            print(f'Epoch {epoch:4d}: Train Loss = {train_loss:.6f}, Test Loss = {test_loss:.6f}')
    
    return train_losses, test_losses, best_test_loss

# ================================
# ç»Ÿè®¡å®éªŒä¸»å‡½æ•°
# ================================

def run_statistical_experiments_2d():
    """è¿è¡Œ2D Navier-Stokesç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯å®éªŒ"""
    device, base_path = setup_colab_environment()
    
    # åŠ è½½æ•°æ®
    train_a, train_u, test_a, test_u = load_navier_stokes_data()
    train_loader, test_loader = prepare_data_loaders_2d(train_a, train_u, test_a, test_u)
    
    # å®éªŒé…ç½®
    n_runs = 5
    epochs = 300
    
    results = {
        'fno_baseline': {'runs': [], 'mean': 0, 'std': 0},
        'fno_rc': {'runs': [], 'mean': 0, 'std': 0},
        'metadata': {
            'problem': '2D Navier-Stokes',
            'n_runs': n_runs,
            'epochs': epochs,
            'device': str(device),
            'timestamp': datetime.now().isoformat(),
            'data_shape': f"train: {train_a.shape}, test: {test_a.shape}"
        }
    }
    
    print("="*60)
    print("2D Navier-Stokes ç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯å®éªŒ")
    print("="*60)
    
    # è¿è¡ŒåŸºçº¿FNOå®éªŒ
    print("\n1. åŸºçº¿FNOå®éªŒ")
    print("-" * 40)
    
    for run in range(n_runs):
        print(f"\nè¿è¡Œ {run+1}/{n_runs}...")
        
        torch.manual_seed(42 + run)
        np.random.seed(42 + run)
        
        model = StandardFNO2d(modes1=12, modes2=12, width=32, num_layers=4)
        
        save_path = f"{base_path}/models/2d_ns/fno_baseline_run_{run+1}.pt"
        train_losses, test_losses, best_test_loss = train_model_2d(
            model, train_loader, test_loader, device, epochs, save_path=save_path
        )
        
        results['fno_baseline']['runs'].append({
            'run': run + 1,
            'best_test_loss': best_test_loss,
            'final_train_loss': train_losses[-1],
            'final_test_loss': test_losses[-1]
        })
        
        print(f"åŸºçº¿FNOè¿è¡Œ {run+1} å®Œæˆ: æœ€ä½³æµ‹è¯•è¯¯å·® = {best_test_loss:.6f}")
        
        del model
        torch.cuda.empty_cache()
    
    # è¿è¡ŒFNO-RCå®éªŒ
    print("\n2. FNO-RCå®éªŒ")
    print("-" * 40)
    
    for run in range(n_runs):
        print(f"\nè¿è¡Œ {run+1}/{n_runs}...")
        
        torch.manual_seed(42 + run)
        np.random.seed(42 + run)
        
        model = FNORCF2d(modes1=12, modes2=12, width=32, num_layers=4,
                        cft_segments=4, cft_modes1=8, cft_modes2=8)
        
        save_path = f"{base_path}/models/2d_ns/fno_rc_run_{run+1}.pt"
        train_losses, test_losses, best_test_loss = train_model_2d(
            model, train_loader, test_loader, device, epochs, save_path=save_path
        )
        
        results['fno_rc']['runs'].append({
            'run': run + 1,
            'best_test_loss': best_test_loss,
            'final_train_loss': train_losses[-1],
            'final_test_loss': test_losses[-1]
        })
        
        print(f"FNO-RCè¿è¡Œ {run+1} å®Œæˆ: æœ€ä½³æµ‹è¯•è¯¯å·® = {best_test_loss:.6f}")
        
        del model
        torch.cuda.empty_cache()
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    fno_errors = [run['best_test_loss'] for run in results['fno_baseline']['runs']]
    fno_rc_errors = [run['best_test_loss'] for run in results['fno_rc']['runs']]
    
    results['fno_baseline']['mean'] = np.mean(fno_errors)
    results['fno_baseline']['std'] = np.std(fno_errors)
    
    results['fno_rc']['mean'] = np.mean(fno_rc_errors)
    results['fno_rc']['std'] = np.std(fno_rc_errors)
    
    improvement = (results['fno_baseline']['mean'] - results['fno_rc']['mean']) / results['fno_baseline']['mean'] * 100
    results['improvement_percent'] = improvement
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
    from scipy import stats
    t_stat, p_value = stats.ttest_rel(fno_errors, fno_rc_errors)
    results['statistical_test'] = {
        't_statistic': float(t_stat),
        'p_value': float(p_value),
        'significant': p_value < 0.05
    }
    
    # ä¿å­˜ç»“æœ
    results_path = f"{base_path}/results/statistical_validation_2d/2d_navier_stokes_statistical_results.json"
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("2D Navier-Stokes ç»Ÿè®¡å®éªŒç»“æœ")
    print("="*60)
    print(f"åŸºçº¿FNO:  {results['fno_baseline']['mean']:.6f} Â± {results['fno_baseline']['std']:.6f}")
    print(f"FNO-RC:   {results['fno_rc']['mean']:.6f} Â± {results['fno_rc']['std']:.6f}")
    print(f"æ”¹è¿›:     {improvement:.2f}%")
    print(f"på€¼:      {p_value:.6f}")
    print(f"ç»Ÿè®¡æ˜¾è‘—: {'æ˜¯' if p_value < 0.05 else 'å¦'}")
    
    # ç”Ÿæˆå¯è§†åŒ–
    create_statistical_plots_2d(results, base_path)
    
    return results

def create_statistical_plots_2d(results, base_path):
    """åˆ›å»º2Dç»Ÿè®¡ç»“æœå¯è§†åŒ–"""
    plt.figure(figsize=(15, 10))
    
    # å­å›¾1: è¯¯å·®å¯¹æ¯”
    plt.subplot(2, 2, 1)
    fno_errors = [run['best_test_loss'] for run in results['fno_baseline']['runs']]
    fno_rc_errors = [run['best_test_loss'] for run in results['fno_rc']['runs']]
    
    x = np.arange(len(fno_errors))
    plt.plot(x, fno_errors, 'o-', label='Standard FNO', linewidth=2, markersize=8, color='red')
    plt.plot(x, fno_rc_errors, 's-', label='FNO-RC', linewidth=2, markersize=8, color='blue')
    plt.xlabel('Run Number')
    plt.ylabel('Test Error')
    plt.title('2D Navier-Stokes: Test Error Across Multiple Runs')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2: ç®±çº¿å›¾
    plt.subplot(2, 2, 2)
    plt.boxplot([fno_errors, fno_rc_errors], labels=['Standard FNO', 'FNO-RC'])
    plt.ylabel('Test Error')
    plt.title('Error Distribution')
    plt.grid(True, alpha=0.3)
    
    # å­å›¾3: æ”¹è¿›ç™¾åˆ†æ¯”
    plt.subplot(2, 2, 3)
    improvements = [(fno_errors[i] - fno_rc_errors[i]) / fno_errors[i] * 100 for i in range(len(fno_errors))]
    plt.bar(range(len(improvements)), improvements, alpha=0.7, color='green')
    plt.xlabel('Run Number')
    plt.ylabel('Improvement (%)')
    plt.title('Improvement Percentage per Run')
    plt.grid(True, alpha=0.3)
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
    for i, imp in enumerate(improvements):
        plt.text(i, imp + max(improvements)*0.01, f'{imp:.1f}%', ha='center', va='bottom')
    
    # å­å›¾4: ç»Ÿè®¡æ±‡æ€»
    plt.subplot(2, 2, 4)
    plt.text(0.1, 0.8, f"Standard FNO: {results['fno_baseline']['mean']:.6f} Â± {results['fno_baseline']['std']:.6f}", 
             fontsize=12, transform=plt.gca().transAxes)
    plt.text(0.1, 0.7, f"FNO-RC: {results['fno_rc']['mean']:.6f} Â± {results['fno_rc']['std']:.6f}", 
             fontsize=12, transform=plt.gca().transAxes)
    plt.text(0.1, 0.6, f"Improvement: {results['improvement_percent']:.2f}%", 
             fontsize=12, transform=plt.gca().transAxes, color='green', weight='bold')
    plt.text(0.1, 0.5, f"p-value: {results['statistical_test']['p_value']:.6f}", 
             fontsize=12, transform=plt.gca().transAxes)
    plt.text(0.1, 0.4, f"Statistically Significant: {'Yes' if results['statistical_test']['significant'] else 'No'}", 
             fontsize=12, transform=plt.gca().transAxes, 
             color='green' if results['statistical_test']['significant'] else 'red', weight='bold')
    plt.axis('off')
    plt.title('Statistical Summary')
    
    plt.tight_layout()
    plt.savefig(f"{base_path}/results/statistical_validation_2d/2d_statistical_comparison.png", 
                dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"2Dç»Ÿè®¡ç»“æœå›¾è¡¨å·²ä¿å­˜åˆ°: {base_path}/results/statistical_validation_2d/")

# ================================
# ä¸»æ‰§è¡Œå‡½æ•°
# ================================

if __name__ == "__main__":
    print("FNO-RC 2D Navier-Stokes ç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯å®éªŒ")
    print("é€‚ç”¨äºGoogle Colabç¯å¢ƒ")
    print("ä¸“æ³¨äº73.68%æ”¹è¿›çš„æœ€æ˜¾è‘—ç»“æœ")
    print("é¢„è®¡è¿è¡Œæ—¶é—´: 4-5å°æ—¶")
    
    # è¿è¡Œå®éªŒ
    results = run_statistical_experiments_2d()
    
    print("\nğŸ‰ 2D Navier-Stokesç»Ÿè®¡éªŒè¯å®éªŒå®Œæˆï¼")
    print("è¿™æ˜¯æ”¹è¿›æœ€æ˜¾è‘—çš„ç»´åº¦ï¼Œç»“æœæœ€æœ‰è¯´æœåŠ›ã€‚")
    print("ç»“æœå·²ä¿å­˜åˆ°Google Driveã€‚")
