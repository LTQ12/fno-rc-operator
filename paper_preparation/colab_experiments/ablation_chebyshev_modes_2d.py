"""
Chebyshevå¤šé¡¹å¼é˜¶æ•°æ¶ˆèå®éªŒ - 2D Navier-Stokes
æµ‹è¯•ä¸åŒM_chebå€¼å¯¹FNO-RCæ€§èƒ½çš„å½±å“ï¼š4, 8, 16, 32ä¸ªmodes

ç›®çš„ï¼šéªŒè¯Chebyshevå¤šé¡¹å¼é˜¶æ•°çš„é‡è¦æ€§å’Œæœ€ä¼˜è®¾ç½®
åŸºäºCFTåˆ†æ®µå®éªŒçš„å‘ç°ï¼Œå›ºå®šL_segments=8
"""

import torch
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import json
import os
from timeit import default_timer
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥æ‚¨å·¥ä½œåŒºçš„ç°æœ‰æ¨¡å—
from fourier_2d_cft_residual import FNO_RC
from utilities3 import GaussianNormalizer, LpLoss, count_params
from Adam import Adam

def setup_colab_environment():
    """è®¾ç½®Colabç¯å¢ƒ"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    base_path = "/content/drive/MyDrive/FNO_RC_Experiments"
    os.makedirs(f"{base_path}/results/ablation_chebyshev_modes", exist_ok=True)
    os.makedirs(f"{base_path}/models/ablation", exist_ok=True)
    
    return device, base_path

def load_ns_data():
    """åŠ è½½2D Navier-Stokesæ•°æ®"""
    print("Loading 2D Navier-Stokes data...")
    
    data_file = "/content/drive/MyDrive/ns_data_N600_clean.pt"
    
    try:
        data = torch.load(data_file, map_location='cpu')
        if data.dim() > 4: 
            data = data.squeeze()
        print(f"Successfully loaded NS data from {data_file}")
        print(f"Data shape: {data.shape}")
        print(f"Data type: {data.dtype}")
        print(f"Data range: [{data.min():.6f}, {data.max():.6f}]")
        
        if torch.isnan(data).any():
            print("âš ï¸  Warning: Found NaN values in data")
        if torch.isinf(data).any():
            print("âš ï¸  Warning: Found Inf values in data")
        
        return data
        
    except FileNotFoundError:
        print(f"âŒ Error: Data file not found at {data_file}")
        print("Please ensure the data file exists at the specified path.")
        raise
    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        raise

class FNO_RC_Chebyshev_Ablation(nn.Module):
    """FNO-RCæ¨¡å‹ï¼Œæ”¯æŒå¯è°ƒèŠ‚çš„Chebyshevå‚æ•°"""
    def __init__(self, modes1, modes2, width, in_channels, out_channels, L_segments=8, M_cheb=8):
        super(FNO_RC_Chebyshev_Ablation, self).__init__()
        self.modes1 = modes1
        self.modes2 = modes2
        self.width = width
        self.padding = 9
        self.fc0 = nn.Linear(in_channels + 2, self.width)

        # ä½¿ç”¨å¯è°ƒèŠ‚å‚æ•°çš„SpectralConv2d_RC
        from fourier_2d_cft_residual import SpectralConv2d_RC
        self.conv0 = SpectralConv2d_RC(self.width, self.width, self.modes1, self.modes2, L_segments, M_cheb)
        self.conv1 = SpectralConv2d_RC(self.width, self.width, self.modes1, self.modes2, L_segments, M_cheb)
        self.conv2 = SpectralConv2d_RC(self.width, self.width, self.modes1, self.modes2, L_segments, M_cheb)
        self.conv3 = SpectralConv2d_RC(self.width, self.width, self.modes1, self.modes2, L_segments, M_cheb)
        
        self.w0 = nn.Conv2d(self.width, self.width, 1)
        self.w1 = nn.Conv2d(self.width, self.width, 1)
        self.w2 = nn.Conv2d(self.width, self.width, 1)
        self.w3 = nn.Conv2d(self.width, self.width, 1)

        self.fc1 = nn.Linear(self.width, 128)
        self.fc2 = nn.Linear(128, out_channels)

    def forward(self, x):
        grid = self.get_grid(x.shape, x.device)
        x = torch.cat((x, grid), dim=-1)
        x = self.fc0(x)
        x = x.permute(0, 3, 1, 2)
        x = F.pad(x, [0, self.padding, 0, self.padding])

        x1 = self.conv0(x)
        x2 = self.w0(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv1(x)
        x2 = self.w1(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv2(x)
        x2 = self.w2(x)
        x = x1 + x2
        x = F.gelu(x)

        x1 = self.conv3(x)
        x2 = self.w3(x)
        x = x1 + x2

        x = x[..., :-self.padding, :-self.padding]
        x = x.permute(0, 2, 3, 1)
        x = self.fc1(x)
        x = F.gelu(x)
        x = self.fc2(x)
        return x
    
    def get_grid(self, shape, device):
        batchsize, size_x, size_y = shape[0], shape[1], shape[2]
        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)
        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])
        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)
        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])
        return torch.cat((gridx, gridy), dim=-1).to(device)

def train_fno_rc_chebyshev_ablation(data, device, M_cheb, epochs=200, ntrain=1000, ntest=200, 
                                   T_in=10, T_out=10, batch_size=20, learning_rate=0.0001, 
                                   modes=16, width=32, L_segments=8, weight_decay=1e-4):
    """è®­ç»ƒFNO-RC Chebyshevæ¶ˆèå®éªŒæ¨¡å‹"""
    
    print(f"ğŸ”§ FNO-RC (M_cheb={M_cheb}): lr={learning_rate}, epochs={epochs}, ntrain={ntrain}, ntest={ntest}")
    
    # æ•°æ®åˆ†å‰² - å®Œå…¨æŒ‰ç…§train_cft_residual_ns_2d.pyæ–¹å¼
    x_train = data[:ntrain, ..., :T_in]
    y_train = data[:ntrain, ..., T_in:T_in+T_out]
    x_test = data[-ntest:, ..., :T_in]
    y_test = data[-ntest:, ..., T_in:T_in+T_out]
    
    # æ•°æ®å½’ä¸€åŒ– - å®Œå…¨æŒ‰ç…§train_cft_residual_ns_2d.pyæ–¹å¼
    x_normalizer = GaussianNormalizer(x_train)
    x_train = x_normalizer.encode(x_train)
    x_test = x_normalizer.encode(x_test)

    y_normalizer = GaussianNormalizer(y_train)
    y_train = y_normalizer.encode(y_train)
    
    train_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(x_train, y_train), 
        batch_size=batch_size, shuffle=True
    )
    test_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(x_test, y_test), 
        batch_size=batch_size, shuffle=False
    )
    
    # æ¨¡å‹åˆå§‹åŒ– - ä½¿ç”¨Chebyshevæ¶ˆèç‰ˆæœ¬
    model = FNO_RC_Chebyshev_Ablation(
        modes1=modes, 
        modes2=modes, 
        width=width,
        in_channels=T_in,
        out_channels=T_out,
        L_segments=L_segments,
        M_cheb=M_cheb
    ).to(device)
    
    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    loss_func = LpLoss(size_average=False)
    
    print(f"  å‚æ•°é‡: {count_params(model)}")
    
    # è®­ç»ƒå¾ªç¯ - å®Œå…¨æŒ‰ç…§train_cft_residual_ns_2d.pyæ–¹å¼
    for ep in range(epochs):
        model.train()
        t1 = default_timer()
        train_l2 = 0
        
        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            out = model(x)
            
            # æŒ‰ç…§train_cft_residual_ns_2d.pyæ–¹å¼ - ç¼–ç çŠ¶æ€ä¸‹è®¡ç®—è®­ç»ƒæŸå¤±
            loss = loss_func(out.view(out.size(0), -1), y.view(y.size(0), -1))
            loss.backward()
            
            optimizer.step()
            train_l2 += loss.item()
        
        scheduler.step()
        
        # æµ‹è¯•è¯„ä¼° - å®Œå…¨æŒ‰ç…§train_cft_residual_ns_2d.pyæ–¹å¼
        model.eval()
        test_l2 = 0.0
        with torch.no_grad():
            y_normalizer.to(device)
            for x, y in test_loader:
                x, y = x.to(device), y.to(device)
                out = model(x)
                
                # æŒ‰ç…§train_cft_residual_ns_2d.pyæ–¹å¼ - è§£ç åè®¡ç®—æµ‹è¯•è¯¯å·®
                out_decoded = y_normalizer.decode(out)
                test_l2 += loss_func(out_decoded.view(out.size(0), -1), y.view(y.size(0), -1)).item()
        
        train_l2 /= ntrain
        test_l2 /= ntest
        
        t2 = default_timer()
        if ep % 50 == 0 or ep == epochs - 1:
            print(f'Epoch {ep+1}/{epochs}: Train L2={train_l2:.6f}, Test L2={test_l2:.6f}')
    
    return test_l2

def run_chebyshev_modes_ablation():
    """è¿è¡ŒChebyshevå¤šé¡¹å¼é˜¶æ•°æ¶ˆèå®éªŒ"""
    device, base_path = setup_colab_environment()
    
    # åŠ è½½æ•°æ®
    data = load_ns_data()
    
    print("="*80)
    print("Chebyshevå¤šé¡¹å¼é˜¶æ•°æ¶ˆèå®éªŒ - 2D Navier-Stokes")
    print("="*80)
    print("ğŸ“‹ å®éªŒè®¾ç½®:")
    print("æµ‹è¯•M_cheb: [6, 8, 10, 12]")
    print("å›ºå®šL_segments: 8 (åŸºäºä¹‹å‰å®éªŒçš„æœ€ä¼˜ç»“æœ)")
    print("å›ºå®šå…¶ä»–å‚æ•°: lr=0.0001, epochs=200, ntrain=1000, ntest=200")
    print("ğŸ’¡ ç»†è‡´æ¢ç´¢M=8é™„è¿‘çš„æœ€ä¼˜åŒºé—´")
    print("="*80)
    
    # å®éªŒå‚æ•°
    EPOCHS = 200  # è¶³å¤Ÿæ”¶æ•›
    M_CHEB_LIST = [6, 8, 10, 12]  # è¦æµ‹è¯•çš„Chebyshevé˜¶æ•°ï¼Œç»†è‡´æ¢ç´¢æœ€ä¼˜åŒºé—´
    L_SEGMENTS = 8  # å›ºå®šä¸ºæœ€ä¼˜åˆ†æ®µæ•°é‡
    
    results = {
        'experiment_type': 'chebyshev_modes_ablation',
        'fixed_parameters': {
            'L_segments': L_SEGMENTS,
            'modes': 16,
            'width': 32,
            'learning_rate': 0.0001,
            'epochs': EPOCHS,
            'ntrain': 1000,
            'ntest': 200,
            'batch_size': 20,
            'weight_decay': 1e-4
        },
        'variable_parameter': 'M_cheb',
        'results': [],
        'baseline_comparison': {
            'baseline_fno_error': 0.088803,  # æ¥è‡ªç»Ÿè®¡éªŒè¯
            'original_fno_rc_error': 0.024504,  # åŸå§‹L=4,M=8çš„ç»“æœ
            'optimal_segments_error': 0.028079,  # L=8,M=8çš„ç»“æœ
            'original_improvement': 72.41,
            'segments_improvement': 68.38
        },
        'metadata': {
            'problem': '2D Navier-Stokes',
            'timestamp': datetime.now().isoformat(),
            'data_file': '/content/drive/MyDrive/ns_data_N600_clean.pt',
            'note': 'Using optimal L_segments=8 from previous ablation experiment'
        }
    }
    
    print(f"ğŸš€ å¼€å§‹Chebyshevå¤šé¡¹å¼é˜¶æ•°æ¶ˆèå®éªŒ...")
    print(f"ğŸ“Œ ä½¿ç”¨æœ€ä¼˜L_segments={L_SEGMENTS}")
    
    for M_cheb in M_CHEB_LIST:
        print(f"\n{'='*20} M_cheb = {M_cheb} {'='*20}")
        
        torch.manual_seed(42)  # å›ºå®šéšæœºç§å­ç¡®ä¿å…¬å¹³æ¯”è¾ƒ
        np.random.seed(42)
        
        # è®­ç»ƒæ¨¡å‹
        test_error = train_fno_rc_chebyshev_ablation(
            data, device,
            M_cheb=M_cheb,
            epochs=EPOCHS,
            L_segments=L_SEGMENTS
        )
        
        # è®¡ç®—ç›¸å¯¹äºåŸºçº¿FNOçš„æ”¹è¿›
        baseline_error = results['baseline_comparison']['baseline_fno_error']
        improvement = (baseline_error - test_error) / baseline_error * 100
        
        # è®¡ç®—ç›¸å¯¹äºåŸå§‹è®¾ç½®å’Œæœ€ä¼˜åˆ†æ®µè®¾ç½®çš„æ¯”è¾ƒ
        original_ratio = test_error / results['baseline_comparison']['original_fno_rc_error']
        segments_ratio = test_error / results['baseline_comparison']['optimal_segments_error']
        
        result = {
            'M_cheb': M_cheb,
            'test_error': test_error,
            'improvement_vs_baseline': improvement,
            'relative_to_original': original_ratio,
            'relative_to_optimal_segments': segments_ratio
        }
        
        results['results'].append(result)
        
        print(f"âœ… M_cheb={M_cheb} å®Œæˆ:")
        print(f"  æµ‹è¯•è¯¯å·®: {test_error:.6f}")
        print(f"  vs åŸºçº¿FNOæ”¹è¿›: {improvement:.2f}%")
        print(f"  vs åŸå§‹FNO-RC(L=4,M=8): {original_ratio:.3f}x")
        print(f"  vs æœ€ä¼˜åˆ†æ®µ(L=8,M=8): {segments_ratio:.3f}x")
        
        torch.cuda.empty_cache()
    
    # åˆ†æç»“æœ
    print("\n" + "="*80)
    print("Chebyshevå¤šé¡¹å¼é˜¶æ•°æ¶ˆèå®éªŒç»“æœ")
    print("="*80)
    
    print("ğŸ“Š è¯¦ç»†ç»“æœ:")
    print(f"{'M_cheb':<8} {'Test Error':<12} {'vs FNO':<12} {'vs L=4,M=8':<12} {'vs L=8,M=8':<12}")
    print("-" * 65)
    
    best_cheb = None
    best_error = float('inf')
    
    for result in results['results']:
        M_cheb = result['M_cheb']
        error = result['test_error']
        improvement = result['improvement_vs_baseline']
        original_ratio = result['relative_to_original']
        segments_ratio = result['relative_to_optimal_segments']
        
        print(f"{M_cheb:<8} {error:<12.6f} {improvement:<12.2f}% {original_ratio:<12.3f}x {segments_ratio:<12.3f}x")
        
        if error < best_error:
            best_error = error
            best_cheb = M_cheb
    
    print("\nğŸ¯ å…³é”®å‘ç°:")
    print(f"  æœ€ä½³M_cheb: {best_cheb}")
    print(f"  æœ€ä½³æµ‹è¯•è¯¯å·®: {best_error:.6f}")
    print(f"  åŸå§‹è®¾ç½®(L=4,M=8): {results['baseline_comparison']['original_fno_rc_error']:.6f}")
    print(f"  æœ€ä¼˜åˆ†æ®µ(L=8,M=8): {results['baseline_comparison']['optimal_segments_error']:.6f}")
    
    # åˆ†æè¶‹åŠ¿
    errors = [r['test_error'] for r in results['results']]
    cheb_modes = [r['M_cheb'] for r in results['results']]
    
    print(f"\nğŸ“ˆ è¶‹åŠ¿åˆ†æ:")
    if best_cheb == 8:
        print("  âœ… åŸå§‹è®¾ç½®(M=8)åœ¨æ–°çš„L=8é…ç½®ä¸‹ä»æ˜¯æœ€ä¼˜çš„")
    elif best_cheb == 6:
        print("  ğŸ“‰ ç•¥å°‘çš„Chebyshevé˜¶æ•°è¡¨ç°æ›´å¥½ï¼ŒM=8å¯èƒ½ç•¥å¾®è¿‡æ‹Ÿåˆ")
    elif best_cheb in [10, 12]:
        print("  ğŸ“ˆ ç•¥å¤šçš„Chebyshevé˜¶æ•°è¡¨ç°æ›´å¥½ï¼Œæ›´é«˜é˜¶å¤šé¡¹å¼æœ‰åŠ©äºæ€§èƒ½")
        if best_cheb == 12:
            print("  ğŸ” M=12è¡¨ç°æœ€ä½³ï¼Œåœ¨è®¡ç®—æ•ˆç‡å’Œç²¾åº¦é—´æ‰¾åˆ°äº†æ›´å¥½å¹³è¡¡")
    
    # è®¡ç®—æœ€ä¼˜ç»„åˆçš„æ€»ä½“æ”¹è¿›
    if best_error < results['baseline_comparison']['optimal_segments_error']:
        total_improvement = (baseline_error - best_error) / baseline_error * 100
        print(f"\nğŸŒŸ æœ€ä¼˜ç»„åˆ (L={L_SEGMENTS}, M={best_cheb}):")
        print(f"  æ€»ä½“æ”¹è¿›: {total_improvement:.2f}% (vs åŸºçº¿FNO)")
        print(f"  ç›¸æ¯”åŸå§‹FNO-RCæ”¹è¿›: {(results['baseline_comparison']['original_fno_rc_error'] - best_error) / results['baseline_comparison']['original_fno_rc_error'] * 100:.2f}%")
    
    # ä¿å­˜ç»“æœ
    results_path = f"{base_path}/results/ablation_chebyshev_modes/chebyshev_modes_ablation_results.json"
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    return results

# ================================
# ä¸»æ‰§è¡Œ
# ================================

if __name__ == "__main__":
    print("ğŸ”¬ Chebyshevå¤šé¡¹å¼é˜¶æ•°æ¶ˆèå®éªŒ")
    print("ğŸ“‹ æµ‹è¯•M_cheb=[6,8,10,12]å¯¹FNO-RCæ€§èƒ½çš„å½±å“")
    print("ğŸ¯ éªŒè¯Chebyshevå¤šé¡¹å¼é˜¶æ•°çš„é‡è¦æ€§å’Œæœ€ä¼˜è®¾ç½®")
    print("ğŸ“Œ åŸºäºL_segments=8çš„æœ€ä¼˜å‘ç°")
    print("ğŸ’¡ ç»†è‡´æ¢ç´¢M=8é™„è¿‘çš„æœ€ä¼˜åŒºé—´")
    print("ğŸ“ æ•°æ®è·¯å¾„: /content/drive/MyDrive/ns_data_N600_clean.pt")
    print("ğŸ• é¢„è®¡è¿è¡Œæ—¶é—´: 1.5-2å°æ—¶")
    print()
    
    results = run_chebyshev_modes_ablation()
    
    print("\nğŸ‰ Chebyshevå¤šé¡¹å¼é˜¶æ•°æ¶ˆèå®éªŒå®Œæˆï¼")
    print("âœ… éªŒè¯äº†ä¸åŒM_chebè®¾ç½®çš„å½±å“")
    print("âœ… ä¸ºFNO-RCçš„CFTå‚æ•°é€‰æ‹©æä¾›äº†å®Œæ•´ä¾æ®")
    print("ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°Google Drive")
