#!/usr/bin/env python3
"""
ç¬¬ä¸€é˜¶æ®µ3Då¯¹æ¯”å®éªŒ: FNO-3D vs B-DeepONet-3D vs FNO-RC-3D
æ•°æ®: 3D Navier-Stokes (ns_V1e-4_N10000_T30.mat)
ç›®æ ‡: éªŒè¯FNO-RCåœ¨é«˜ç»´å¤æ‚é—®é¢˜ä¸Šçš„ä¼˜åŠ¿
"""
import torch
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import argparse
from timeit import default_timer
import os
import json
from datetime import datetime
import matplotlib.pyplot as plt

# å¯¼å…¥é¡¹ç›®æ¨¡å—
import sys
sys.path.append('/content/fourier_neural_operator-master')

# å¯¼å…¥æ¨¡å‹
from fourier_3d_cft_residual import FNO_RC_3D
from fourier_3d_baseline_reliable import FNO3d_Baseline
from b_deeponet_3d import BDeepONet3D_Simplified

# å¯¼å…¥å·¥å…·
from utilities3 import LpLoss, count_params, MatReader, UnitGaussianNormalizer
from Adam import Adam

torch.manual_seed(42)  # ä½¿ç”¨ä¸åŒçš„éšæœºç§å­ç¡®ä¿å…¬å¹³æ€§
np.random.seed(42)

class ExperimentTracker:
    """å®éªŒè·Ÿè¸ªå™¨"""
    def __init__(self, save_dir):
        self.save_dir = save_dir
        self.results = {}
        self.start_time = datetime.now()
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
    def log_model_info(self, model_name, model, args):
        """è®°å½•æ¨¡å‹ä¿¡æ¯"""
        self.results[model_name] = {
            'model_info': {
                'parameters': count_params(model),
                'modes': args.modes,
                'width': args.width,
                'learning_rate': args.learning_rate,
                'epochs': args.epochs,
                'batch_size': args.batch_size
            },
            'training_history': {
                'train_loss': [],
                'test_loss': [],
                'epoch_times': []
            },
            'final_results': {}
        }
        
    def log_epoch(self, model_name, epoch, train_loss, test_loss, epoch_time):
        """è®°å½•æ¯ä¸ªepochçš„ç»“æœ"""
        self.results[model_name]['training_history']['train_loss'].append(train_loss)
        self.results[model_name]['training_history']['test_loss'].append(test_loss)
        self.results[model_name]['training_history']['epoch_times'].append(epoch_time)
        
    def log_final_results(self, model_name, final_train_loss, final_test_loss, total_time):
        """è®°å½•æœ€ç»ˆç»“æœ"""
        self.results[model_name]['final_results'] = {
            'final_train_loss': final_train_loss,
            'final_test_loss': final_test_loss,
            'total_training_time': total_time,
            'avg_epoch_time': np.mean(self.results[model_name]['training_history']['epoch_times'])
        }
        
    def save_results(self):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        # è®¡ç®—ç›¸å¯¹æ”¹è¿›
        if 'FNO_Baseline' in self.results and 'FNO_RC' in self.results:
            baseline_error = self.results['FNO_Baseline']['final_results']['final_test_loss']
            fno_rc_error = self.results['FNO_RC']['final_results']['final_test_loss']
            improvement = (baseline_error - fno_rc_error) / baseline_error * 100
            self.results['comparison'] = {
                'fno_rc_vs_baseline_improvement': f"{improvement:.2f}%"
            }
        
        # ä¿å­˜JSONç»“æœ
        results_file = os.path.join(self.save_dir, 'phase1_3d_comparison_results.json')
        with open(results_file, 'w') as f:
            json.dump(self.results, f, indent=2, default=str)
            
        print(f"\nğŸ“Š å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        plt.figure(figsize=(15, 5))
        
        # è®­ç»ƒæŸå¤±
        plt.subplot(1, 3, 1)
        for model_name in self.results.keys():
            if model_name != 'comparison':
                train_losses = self.results[model_name]['training_history']['train_loss']
                epochs = range(1, len(train_losses) + 1)
                plt.plot(epochs, train_losses, label=model_name, linewidth=2)
        plt.xlabel('Epoch')
        plt.ylabel('Training L2 Loss')
        plt.title('Training Loss Curves')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.yscale('log')
        
        # æµ‹è¯•æŸå¤±
        plt.subplot(1, 3, 2)
        for model_name in self.results.keys():
            if model_name != 'comparison':
                test_losses = self.results[model_name]['training_history']['test_loss']
                epochs = range(1, len(test_losses) + 1)
                plt.plot(epochs, test_losses, label=model_name, linewidth=2)
        plt.xlabel('Epoch')
        plt.ylabel('Test L2 Loss')
        plt.title('Test Loss Curves')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.yscale('log')
        
        # æœ€ç»ˆå¯¹æ¯”
        plt.subplot(1, 3, 3)
        model_names = []
        test_errors = []
        for model_name in self.results.keys():
            if model_name != 'comparison':
                model_names.append(model_name)
                test_errors.append(self.results[model_name]['final_results']['final_test_loss'])
        
        bars = plt.bar(model_names, test_errors, 
                      color=['skyblue', 'lightcoral', 'lightgreen'][:len(model_names)])
        plt.xlabel('Model')
        plt.ylabel('Final Test L2 Loss')
        plt.title('Final Performance Comparison')
        plt.yscale('log')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, error in zip(bars, test_errors):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), 
                    f'{error:.6f}', ha='center', va='bottom')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plot_file = os.path.join(self.save_dir, 'phase1_3d_training_curves.png')
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {plot_file}")
        plt.close()

def train_model(model, model_name, train_loader, test_loader, args, device, tracker):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {model_name}")
    print("=" * 60)
    
    # è®°å½•æ¨¡å‹ä¿¡æ¯
    tracker.log_model_info(model_name, model, args)
    
    # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer = Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.scheduler_step, gamma=args.scheduler_gamma)
    loss_func = LpLoss(size_average=False)
    
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {count_params(model):,}")
    print(f"ğŸ”§ è¶…å‚æ•°: modes={args.modes}, width={args.width}, lr={args.learning_rate}")
    
    # è®­ç»ƒå¾ªç¯
    model_start_time = default_timer()
    
    for ep in range(args.epochs):
        model.train()
        epoch_start = default_timer()
        train_l2 = 0
        
        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            
            out = model(x).squeeze(-1)  # ç§»é™¤æœ€åçš„channelç»´åº¦
            loss = loss_func(out, y)
            loss.backward()
            optimizer.step()
            train_l2 += loss.item()
        
        scheduler.step()
        
        # æµ‹è¯•
        model.eval()
        test_l2 = 0.0
        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(device), y.to(device)
                out = model(x).squeeze(-1)
                
                # è§£ç è¿›è¡Œå…¬å¹³æ¯”è¾ƒ
                out_decoded = y_normalizer.decode(out)
                y_decoded = y_normalizer.decode(y)
                test_l2 += loss_func(out_decoded, y_decoded).item()
        
        # å½’ä¸€åŒ–æŸå¤±
        train_l2 /= args.ntrain
        test_l2 /= args.ntest
        
        epoch_time = default_timer() - epoch_start
        
        # è®°å½•ç»“æœ
        tracker.log_epoch(model_name, ep + 1, train_l2, test_l2, epoch_time)
        
        # æ‰“å°è¿›åº¦
        if (ep + 1) % 10 == 0 or ep == 0:
            print(f"Epoch {ep+1:3d}/{args.epochs} | Time: {epoch_time:.2f}s | "
                  f"Train L2: {train_l2:.6f} | Test L2: {test_l2:.6f}")
    
    total_time = default_timer() - model_start_time
    
    # è®°å½•æœ€ç»ˆç»“æœ
    final_train_loss = tracker.results[model_name]['training_history']['train_loss'][-1]
    final_test_loss = tracker.results[model_name]['training_history']['test_loss'][-1]
    tracker.log_final_results(model_name, final_train_loss, final_test_loss, total_time)
    
    print(f"âœ… {model_name} è®­ç»ƒå®Œæˆ!")
    print(f"   æœ€ç»ˆæµ‹è¯•è¯¯å·®: {final_test_loss:.6f}")
    print(f"   æ€»è®­ç»ƒæ—¶é—´: {total_time:.1f}ç§’")
    
    return model

def main():
    # è§£æå‚æ•°
    parser = argparse.ArgumentParser(description='Phase 1: 3D Comparison Experiment')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_path', type=str, 
                       default='/content/drive/MyDrive/ns_V1e-4_N10000_T30.mat')
    parser.add_argument('--save_dir', type=str, 
                       default='/content/drive/MyDrive/FNO_RC_Experiments/phase1_3d_comparison')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--ntrain', type=int, default=1000)
    parser.add_argument('--ntest', type=int, default=200)
    parser.add_argument('--T_in', type=int, default=10)
    parser.add_argument('--T_out', type=int, default=20)
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--modes', type=int, default=8)
    parser.add_argument('--width', type=int, default=20)
    parser.add_argument('--epochs', type=int, default=200)  # å‡å°‘epochsåŠ å¿«å®éªŒ
    parser.add_argument('--batch_size', type=int, default=10)
    parser.add_argument('--learning_rate', type=float, default=0.001)
    parser.add_argument('--weight_decay', type=float, default=1e-4)
    parser.add_argument('--scheduler_step', type=int, default=100)
    parser.add_argument('--scheduler_gamma', type=float, default=0.5)
    
    args = parser.parse_args()
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"ğŸ“± GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # åˆå§‹åŒ–å®éªŒè·Ÿè¸ªå™¨
    tracker = ExperimentTracker(args.save_dir)
    
    print("\n" + "=" * 80)
    print("ğŸ§ª ç¬¬ä¸€é˜¶æ®µ3Då¯¹æ¯”å®éªŒ - FNO vs B-DeepONet vs FNO-RC")
    print("=" * 80)
    print(f"ğŸ“Š å®éªŒè®¾ç½®:")
    print(f"   æ•°æ®é›†: 3D Navier-Stokes (Î½=1e-4)")
    print(f"   è®­ç»ƒæ ·æœ¬: {args.ntrain}, æµ‹è¯•æ ·æœ¬: {args.ntest}")
    print(f"   è¾“å…¥æ—¶é—´æ­¥: {args.T_in}, é¢„æµ‹æ—¶é—´æ­¥: {args.T_out}")
    print(f"   è®­ç»ƒè½®æ•°: {args.epochs}")
    print("=" * 80)
    
    # æ•°æ®åŠ è½½
    print("\nğŸ“‚ åŠ è½½3D Navier-Stokesæ•°æ®...")
    try:
        reader = MatReader(args.data_path)
        u_field = reader.read_field('u')
        print(f"âœ… æ•°æ®å½¢çŠ¶: {u_field.shape}")
        
        # æ•°æ®åˆ’åˆ†
        train_a = u_field[:args.ntrain, ..., :args.T_in]
        train_u = u_field[:args.ntrain, ..., args.T_in:args.T_in + args.T_out]
        test_a = u_field[-args.ntest:, ..., :args.T_in]
        test_u = u_field[-args.ntest:, ..., args.T_in:args.T_in + args.T_out]
        
        print(f"   è®­ç»ƒè¾“å…¥: {train_a.shape}")
        print(f"   è®­ç»ƒè¾“å‡º: {train_u.shape}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ•°æ®é¢„å¤„ç†
    print("\nğŸ”§ æ•°æ®é¢„å¤„ç†...")
    global y_normalizer  # ç”¨äºæµ‹è¯•æ—¶è§£ç 
    
    a_normalizer = UnitGaussianNormalizer(train_a)
    train_a = a_normalizer.encode(train_a)
    test_a = a_normalizer.encode(test_a)
    
    y_normalizer = UnitGaussianNormalizer(train_u)
    train_u = y_normalizer.encode(train_u)
    y_normalizer.to(device)
    
    # é‡å¡‘æ•°æ®ä»¥åŒ¹é…æ¨¡å‹è¾“å…¥æ ¼å¼
    S1, S2 = train_a.shape[1], train_a.shape[2]
    train_a = train_a.reshape(args.ntrain, S1, S2, 1, args.T_in).repeat([1,1,1,args.T_out,1])
    test_a = test_a.reshape(args.ntest, S1, S2, 1, args.T_in).repeat([1,1,1,args.T_out,1])
    
    # æ•°æ®åŠ è½½å™¨
    train_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(train_a, train_u), 
        batch_size=args.batch_size, shuffle=True
    )
    test_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(test_a, test_u), 
        batch_size=args.batch_size, shuffle=False
    )
    
    print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
    
    # æ¨¡å‹å®šä¹‰
    models = {
        'FNO_Baseline': FNO3d_Baseline(
            args.modes, args.modes, args.modes, args.width, 
            in_channels=args.T_in, out_channels=1
        ).to(device),
        
        'B_DeepONet': BDeepONet3D_Simplified(
            args.modes, args.modes, args.modes, args.width,
            in_channels=args.T_in, out_channels=1
        ).to(device),
        
        'FNO_RC': FNO_RC_3D(
            args.modes, args.modes, args.modes, args.width,
            in_channels=args.T_in, out_channels=1
        ).to(device)
    }
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    trained_models = {}
    for model_name, model in models.items():
        trained_models[model_name] = train_model(
            model, model_name, train_loader, test_loader, args, device, tracker
        )
    
    # ä¿å­˜ç»“æœå’Œç»˜åˆ¶å›¾è¡¨
    tracker.save_results()
    tracker.plot_training_curves()
    
    # è¾“å‡ºæœ€ç»ˆå¯¹æ¯”ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ† ç¬¬ä¸€é˜¶æ®µå®éªŒç»“æœæ€»ç»“")
    print("=" * 80)
    
    results_summary = []
    for model_name in ['FNO_Baseline', 'B_DeepONet', 'FNO_RC']:
        if model_name in tracker.results:
            result = tracker.results[model_name]['final_results']
            results_summary.append({
                'model': model_name,
                'test_error': result['final_test_loss'],
                'params': tracker.results[model_name]['model_info']['parameters'],
                'time': result['total_training_time']
            })
    
    # æ’åºå¹¶æ˜¾ç¤º
    results_summary.sort(key=lambda x: x['test_error'])
    
    print(f"{'æ¨¡å‹':<15} {'æµ‹è¯•è¯¯å·®':<12} {'å‚æ•°é‡':<10} {'è®­ç»ƒæ—¶é—´(s)':<12} {'ç›¸å¯¹æ”¹è¿›'}")
    print("-" * 70)
    
    baseline_error = None
    for i, result in enumerate(results_summary):
        if result['model'] == 'FNO_Baseline':
            baseline_error = result['test_error']
            improvement = "åŸºçº¿"
        else:
            if baseline_error:
                improvement = f"{(baseline_error - result['test_error']) / baseline_error * 100:+.1f}%"
            else:
                improvement = "N/A"
        
        print(f"{result['model']:<15} {result['test_error']:<12.6f} {result['params']:<10,} "
              f"{result['time']:<12.1f} {improvement}")
    
    print("=" * 80)
    print("ğŸ‰ ç¬¬ä¸€é˜¶æ®µå®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main()
