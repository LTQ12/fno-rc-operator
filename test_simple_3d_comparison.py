#!/usr/bin/env python3
"""
ç®€åŒ–çš„3Då¯¹æ¯”å®éªŒ - ç›´æ¥å¤åˆ¶2DæˆåŠŸçš„æ€è·¯
å…³é”®ç®€åŒ–ï¼š
1. å»æ‰å¤æ‚çš„å­¦ä¹ æƒé‡
2. ç›´æ¥ä½¿ç”¨2DæˆåŠŸçš„å…¨å±€æ ‡é‡ä¿®æ­£ï¼ˆè™½ç„¶ä¸å®Œç¾ï¼Œä½†è‡³å°‘èƒ½å·¥ä½œï¼‰
3. å¢åŠ CFTæ¨¡æ€æ•°é‡
4. ç®€åŒ–æ¶æ„ï¼Œç¡®ä¿æ¢¯åº¦ä¼ æ’­
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import h5py
import json
import os
from datetime import datetime
from timeit import default_timer

# å¯¼å…¥æ­£ç¡®ç»“æ„çš„æ¨¡å‹
from fourier_3d_clean import FNO3d
from fourier_3d_cft_residual_correct import FNO_RC_3D_Correct
from utilities3 import LpLoss, count_params, UnitGaussianNormalizer, GaussianNormalizer
from Adam import Adam

################################################################
# å¤ç”¨æ•°æ®åŠ è½½å‡½æ•°
################################################################
def load_3d_data_efficient(data_path, ntrain=600, ntest=80, T_in=10, T_out=20):
    """å†…å­˜é«˜æ•ˆçš„æ•°æ®åŠ è½½"""
    print(f"ğŸ“ æ­£åœ¨åŠ è½½æ•°æ®: {data_path}")
    
    try:
        print("â³ æ­£åœ¨è¯»å–.matæ–‡ä»¶ (MATLAB v7.3æ ¼å¼)...")
        with h5py.File(data_path, 'r') as f:
            u_field = f['u'][:]  # [T, H, W, N] -> [50, 64, 64, 10000]
        
        print(f"âœ… åŸå§‹æ•°æ®å½¢çŠ¶: {u_field.shape}")
        
        # è½¬æ¢ä¸ºtensorå¹¶è°ƒæ•´æ ¼å¼: [T, H, W, N] -> [N, H, W, T]
        print("ğŸ”„ æ­£åœ¨è½¬æ¢æ•°æ®æ ¼å¼...")
        u_field = torch.from_numpy(u_field).float()
        u_field = u_field.permute(3, 1, 2, 0)  # [10000, 64, 64, 50]
        print(f"âœ… è½¬æ¢åæ•°æ®å½¢çŠ¶: {u_field.shape}")
        
        # æ§åˆ¶æ ·æœ¬æ•°é‡ä»¥èŠ‚çœå†…å­˜
        total_samples = u_field.shape[0]
        ntrain_actual = min(total_samples - 150, ntrain)
        ntest_actual = min(total_samples - ntrain_actual, ntest)
        
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples}, è®­ç»ƒ: {ntrain_actual}, æµ‹è¯•: {ntest_actual}")
        
        # æ£€æŸ¥æ—¶é—´æ­¥
        if u_field.shape[-1] < T_in + T_out:
            print(f"âŒ æ—¶é—´æ­¥ä¸è¶³: éœ€è¦ {T_in + T_out}, å®é™… {u_field.shape[-1]}")
            return None
        
        print("ğŸ”„ æ­£åœ¨åˆ†å‰²æ•°æ®...")
        train_a = u_field[:ntrain_actual, ..., :T_in]
        train_u = u_field[:ntrain_actual, ..., T_in:T_in + T_out]
        
        test_a = u_field[-ntest_actual:, ..., :T_in]
        test_u = u_field[-ntest_actual:, ..., T_in:T_in + T_out]

        print(f"âœ… æ•°æ®å½¢çŠ¶: train_a: {train_a.shape}, train_u: {train_u.shape}")
        print(f"âœ… æœ€ç»ˆæ ·æœ¬æ•°: ntrain={ntrain_actual}, ntest={ntest_actual}")
        
        # é‡Šæ”¾åŸå§‹æ•°æ®
        del u_field
        import gc
        gc.collect()
        
        return train_a, train_u, test_a, test_u, ntrain_actual, ntest_actual
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def preprocess_3d_data_sequence(train_a, train_u, test_a, test_u, T_in, T_out, device):
    """å®Œæ•´åºåˆ—é¢„æµ‹çš„æ•°æ®é¢„å¤„ç†"""
    
    S1, S2 = train_a.shape[1], train_a.shape[2]
    ntrain_actual, ntest_actual = train_a.shape[0], test_a.shape[0]
    
    # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨GaussianNormalizerè€Œä¸æ˜¯UnitGaussianNormalizer
    # è¿™ä¿æŒäº†ç©ºé—´ç›¸å…³æ€§ï¼Œå¯¹CFTè‡³å…³é‡è¦ï¼
    a_normalizer = GaussianNormalizer(train_a)
    train_a = a_normalizer.encode(train_a)
    test_a = a_normalizer.encode(test_a)

    # æ ‡å‡†åŒ–å®Œæ•´åºåˆ—è¾“å‡º
    y_normalizer = GaussianNormalizer(train_u)
    train_u_normalized = y_normalizer.encode(train_u)
    y_normalizer.to(device)
    
    # æ•°æ®æ ¼å¼è½¬æ¢
    train_a_fno = train_a.reshape(ntrain_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    test_a_fno = test_a.reshape(ntest_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    
    train_a_rc = train_a.reshape(ntrain_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    test_a_rc = test_a.reshape(ntest_actual, S1, S2, 1, T_in).repeat([1,1,1,T_out,1])
    
    print(f"é¢„å¤„ç†å®Œæˆï¼ˆç®€åŒ–æ¶æ„ç‰ˆæœ¬ï¼‰:")
    print(f"  FNOè¾“å…¥: {train_a_fno.shape}, ç›®æ ‡: {train_u_normalized.shape}")
    print(f"  FNO_RC_Simpleè¾“å…¥: {train_a_rc.shape}, ç›®æ ‡: {train_u_normalized.shape}")
    
    return (train_a_fno, train_u_normalized, test_a_fno, test_u, 
            train_a_rc, test_a_rc, y_normalizer, S1, S2)

################################################################
# ç®€åŒ–çš„è®­ç»ƒå‡½æ•°
################################################################
def train_model_simple(model, model_name, train_loader, test_loader, y_normalizer, device, ntrain_actual, ntest_actual, epochs=100):
    """ç®€åŒ–çš„è®­ç»ƒå‡½æ•° - é‡ç‚¹ç›‘æ§CFTè·¯å¾„æ˜¯å¦å·¥ä½œ"""
    print(f"\nğŸ”§ Training {model_name} (Simple Architecture)...")
    print(f"Parameters: {count_params(model):,}")
    
    model.to(device)
    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # ğŸ”§ ä½¿ç”¨æˆåŠŸ3Då®éªŒçš„å­¦ä¹ ç‡
    
    # ğŸ”§ å®Œå…¨å¤åˆ¶æˆåŠŸ3Då®éªŒçš„è°ƒåº¦å™¨ï¼šStepLR
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)
    loss_func = LpLoss(size_average=False)
    
    train_losses = []
    test_losses = []
    
    # æ—©åœæœºåˆ¶
    best_test_loss = float('inf')
    patience = 15
    patience_counter = 0
    
    for ep in range(epochs):
        model.train()
        t1 = default_timer()
        train_l2 = 0
        
        for batch_idx, (x, y) in enumerate(train_loader):
            x, y = x.to(device), y.to(device)
            
            optimizer.zero_grad()
            
            if model_name == 'FNO3d':
                # FNO3d: æ·»åŠ ç½‘æ ¼åæ ‡
                grid = create_grid_for_fno3d(x.shape, device)
                x_with_grid = torch.cat((x, grid), dim=-1)
                out = model(x_with_grid).squeeze(-1)
            elif model_name == 'FNO_RC_3D_Simple':
                # ç®€åŒ–çš„FNO_RC_3D - å®Œå…¨å¤åˆ¶æˆåŠŸå®éªŒçš„ç®€æ´æ–¹å¼
                out = model(x).squeeze(-1)
                
                # ğŸ”§ å¢å¼ºç›‘æ§ï¼šæ¯5ä¸ªepochæ£€æŸ¥FNO-RCçŠ¶æ€
                if ep % 5 == 0 and batch_idx == 0:
                    print(f"  ğŸ” Epoch {ep} è¯Šæ–­:")
                    print(f"    è¾“å‡ºèŒƒå›´: min={out.min().item():.6f}, max={out.max().item():.6f}, std={out.std().item():.6f}")
                    
                    # æ£€æŸ¥æ˜¯å¦å‡ºç°å¼‚å¸¸å€¼
                    if torch.isnan(out).any() or torch.isinf(out).any():
                        print(f"    âŒ æ£€æµ‹åˆ°NaNæˆ–Infï¼")
                    
                    if out.abs().max() > 100:
                        print(f"    âš ï¸  è¾“å‡ºå€¼è¿‡å¤§ï¼Œå¯èƒ½å‘æ•£ï¼")
                    
                    # ğŸ”§ CFTè·¯å¾„è¯¦ç»†ç›‘æ§
                    with torch.no_grad():
                        try:
                            # å¯ç”¨ç›‘æ§æ¨¡å¼
                            for layer in [model.conv0, model.conv1, model.conv2, model.conv3]:
                                layer._monitor_cft = True
                            
                            # è¿è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ä»¥æ”¶é›†ç›‘æ§æ•°æ®
                            x_test = x[:1]
                            _ = model(x_test)
                            
                            # æ£€æŸ¥å„å±‚CFTè·¯å¾„çš„æ´»è·ƒåº¦
                            cft_active_layers = 0
                            total_correction_magnitude = 0.0
                            
                            for i, layer in enumerate([model.conv0, model.conv1, model.conv2, model.conv3]):
                                if hasattr(layer, '_last_correction_magnitude'):
                                    correction_mag = layer._last_correction_magnitude
                                    cft_input_mag = layer._last_cft_input_magnitude
                                    
                                    if correction_mag > 1e-6:  # CFTè·¯å¾„æœ‰æ˜¾è‘—è¾“å‡º
                                        cft_active_layers += 1
                                        total_correction_magnitude += correction_mag
                                    
                                    if i == 0:  # åªæ‰“å°ç¬¬ä¸€å±‚çš„è¯¦ç»†ä¿¡æ¯
                                        print(f"    CFTè·¯å¾„: è¾“å…¥å¹…åº¦={cft_input_mag:.6f}, ä¿®æ­£å¹…åº¦={correction_mag:.6f}")
                            
                            print(f"    CFTæ´»è·ƒå±‚æ•°: {cft_active_layers}/4, æ€»ä¿®æ­£å¹…åº¦: {total_correction_magnitude:.6f}")
                            
                            # è¯Šæ–­CFTä¿®æ­£æ˜¯å¦åˆç†
                            if total_correction_magnitude > 10:
                                print(f"    âš ï¸  CFTä¿®æ­£å¹…åº¦è¿‡å¤§ï¼Œå¯èƒ½ç ´åè®­ç»ƒï¼")
                            elif total_correction_magnitude < 0.001:
                                print(f"    âš ï¸  CFTä¿®æ­£å¹…åº¦è¿‡å°ï¼Œå¯èƒ½æ²¡æœ‰æ•ˆæœï¼")
                            else:
                                print(f"    âœ… CFTä¿®æ­£å¹…åº¦é€‚ä¸­")
                            
                            # å…³é—­ç›‘æ§æ¨¡å¼
                            for layer in [model.conv0, model.conv1, model.conv2, model.conv3]:
                                delattr(layer, '_monitor_cft')
                                
                        except Exception as e:
                            print(f"    âŒ CFTç›‘æ§å¤±è´¥: {e}")
            
            # å®Œæ•´åºåˆ—æŸå¤±è®¡ç®—
            loss_normalized = loss_func(out, y)
            loss_normalized.backward()
            optimizer.step()
            
            # è®°å½•æŸå¤± - ä½¿ç”¨çœŸå®å°ºåº¦æ•°æ®
            with torch.no_grad():
                out_decoded = y_normalizer.decode(out)
                y_decoded = y_normalizer.decode(y)
                loss_real_scale = loss_func(out_decoded, y_decoded)
                train_l2 += loss_real_scale.item()
        
        scheduler.step()
        
        # æµ‹è¯•
        model.eval()
        test_l2 = 0.0
        with torch.no_grad():
            for x, y in test_loader:
                x, y = x.to(device), y.to(device)
                
                if model_name == 'FNO3d':
                    grid = create_grid_for_fno3d(x.shape, device)
                    x_with_grid = torch.cat((x, grid), dim=-1)
                    out = model(x_with_grid).squeeze(-1)
                elif model_name == 'FNO_RC_3D_Simple':
                    out = model(x).squeeze(-1)
                
                # å®Œæ•´åºåˆ—æµ‹è¯•æŸå¤±
                out_decoded = y_normalizer.decode(out)
                y_decoded = y_normalizer.decode(y)
                test_l2 += loss_func(out_decoded, y_decoded).item()
        
        train_l2 /= ntrain_actual
        test_l2 /= ntest_actual
        
        train_losses.append(train_l2)
        test_losses.append(test_l2)
        
        # æ—©åœæ£€æŸ¥
        if test_l2 < best_test_loss:
            best_test_loss = test_l2
            patience_counter = 0
        else:
            patience_counter += 1
            
        if ep % 10 == 0:
            print(f'Epoch {ep+1}/{epochs}: Train {train_l2:.6f}, Test {test_l2:.6f}')
        
        # æ—©åœ
        if patience_counter >= patience:
            print(f"ğŸ›‘ æ—©åœ: æµ‹è¯•æŸå¤±åœ¨{patience}ä¸ªepochå†…æ²¡æœ‰æ”¹å–„")
            break
    
    return model, train_losses, test_losses

def create_grid_for_fno3d(shape, device):
    """ä¸ºFNO3dåˆ›å»ºç½‘æ ¼åæ ‡"""
    B, H, W, T_dim, _ = shape
    
    h_coords = torch.linspace(0, 1, H, device=device)
    w_coords = torch.linspace(0, 1, W, device=device)
    t_coords = torch.linspace(0, 1, T_dim, device=device)
    
    hh, ww, tt = torch.meshgrid(h_coords, w_coords, t_coords, indexing='ij')
    grid = torch.stack([hh, ww, tt], dim=-1).unsqueeze(0).repeat(B, 1, 1, 1, 1)
    
    return grid

################################################################
# ä¸»å‡½æ•°
################################################################
def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"ğŸ“± GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    print("ğŸ”§ è®¾ç½®Colabç¯å¢ƒ...")
    
    # å‚æ•°è®¾ç½® - ä½¿ç”¨æˆåŠŸå®éªŒçš„é…ç½®
    data_path = '/content/drive/MyDrive/ns_V1e-4_N10000_T30.mat'
    ntrain, ntest = 1000, 200       # ğŸ”§ æ¢å¤æˆåŠŸå®éªŒçš„æ ·æœ¬æ•°
    T_in, T_out = 10, 20            # ä¿æŒå®Œæ•´åºåˆ—é¢„æµ‹
    modes = 8
    width = 20
    batch_size = 10                 # ğŸ”§ æ¢å¤æˆåŠŸå®éªŒçš„batch_size
    epochs = 100                    # ğŸ”§ è®¾ç½®ä¸º100 epochs
    
    print("ğŸš€ å¼€å§‹FNO-RCä¸“é¡¹è°ƒè¯•å®éªŒ")
    print(f"ğŸ“‹ å®éªŒå‚æ•°: epochs={epochs}, batch_size={batch_size}")
    print(f"ğŸ“Š æ•°æ®å‚æ•°: ntrain={ntrain}, ntest={ntest}, T_in={T_in}, T_out={T_out}")
    print("ğŸ¯ è°ƒè¯•ç­–ç•¥: å±è”½FNOè®­ç»ƒï¼Œä¸“æ³¨FNO-RCé—®é¢˜è¯Šæ–­")
    print("ğŸ“ˆ FNOåŸºå‡†: å·²çŸ¥ç¨³å®šåœ¨æµ‹è¯•è¯¯å·®~0.44")
    print("ğŸ”§ FNO-RCé…ç½®: æœ€ç®€å•ç¨³å®šç‰ˆæœ¬")
    print("  - CFTæ¨¡æ€æ¯”ä¾‹: modes//4")
    print("  - ç½‘ç»œç»“æ„: 2å±‚correction_generator") 
    print("  - ä¿®æ­£æ–¹å¼: å…¨å±€æ ‡é‡ä¿®æ­£")
    print("  - åˆå§‹åŒ–: é›¶åˆå§‹åŒ–")
    print("  - æ ‡å‡†åŒ–: GaussianNormalizer")
    print("âš¡ ç›®æ ‡ï¼šè®©FNO-RCæµ‹è¯•è¯¯å·® < 0.44ï¼ˆå³è¶…è¶ŠFNOï¼‰")
    
    # æ•°æ®åŠ è½½
    print("\nğŸ“ æ­¥éª¤1: æ•°æ®åŠ è½½")
    data = load_3d_data_efficient(data_path, ntrain, ntest, T_in, T_out)
    if data is None:
        return
    
    train_a, train_u, test_a, test_u, ntrain_actual, ntest_actual = data
    
    # æ•°æ®é¢„å¤„ç†
    print("\nğŸ”„ æ­¥éª¤2: æ•°æ®é¢„å¤„ç†")
    processed_data = preprocess_3d_data_sequence(train_a, train_u, test_a, test_u, T_in, T_out, device)
    (train_a_fno, train_u, test_a_fno, test_u, 
     train_a_rc, test_a_rc, y_normalizer, S1, S2) = processed_data
    
    # æ•°æ®åŠ è½½å™¨
    train_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(train_a_fno, train_u), 
        batch_size=batch_size, shuffle=True
    )
    test_loader = torch.utils.data.DataLoader(
        torch.utils.data.TensorDataset(test_a_fno, test_u), 
        batch_size=batch_size, shuffle=False
    )
    
    # ğŸ”§ ä¸“æ³¨è°ƒè¯•FNO-RCï¼šæš‚æ—¶å±è”½FNOè®­ç»ƒ
    models = {
        # 'FNO3d': FNO3d(modes, modes, modes, width, in_dim=13, out_dim=1),  # æš‚æ—¶å±è”½ï¼Œä¸“æ³¨FNO-RCè°ƒè¯•
        'FNO_RC_3D_Correct': FNO_RC_3D_Correct(modes, modes, modes, width, in_channels=T_in, out_channels=1),
    }

    print(f"ğŸ“Š æ¨¡å‹é…ç½®:")
    for name, model in models.items():
        print(f"  {name}: {count_params(model):,} å‚æ•°")

    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    print("\nğŸ‹ï¸ æ­¥éª¤3: å¼€å§‹è®­ç»ƒæ¨¡å‹")
    results = {}
    for model_name, model in models.items():
        trained_model, train_losses, test_losses = train_model_simple(
            model, model_name, train_loader, test_loader, y_normalizer, device, ntrain_actual, ntest_actual, epochs
        )
        
        final_test_loss = test_losses[-1]
        results[model_name] = {
            'final_test_loss': final_test_loss,
            'train_losses': train_losses,
            'test_losses': test_losses,
            'parameters': count_params(model)
        }
        print(f"âœ… {model_name}: {final_test_loss:.6f}")

    # FNO-RCä¸“é¡¹è°ƒè¯•ç»“æœ
    print(f"\nğŸ† FNO-RCä¸“é¡¹è°ƒè¯•ç»“æœ (æ­£ç¡®æ¶æ„ - {epochs} epochs):")
    print("-" * 60)

    for name, result in results.items():
        print(f"ğŸ”§ {name}: {result['final_test_loss']:.6f} ({result['parameters']:,} å‚æ•°)")
        
        # ä¸å·²çŸ¥FNOåŸºå‡†å¯¹æ¯” (çº¦0.44)
        fno_baseline = 0.44  # å·²çŸ¥çš„FNO3dåŸºå‡†æ€§èƒ½
        if result['final_test_loss'] < fno_baseline:
            improvement = (fno_baseline - result['final_test_loss']) / fno_baseline * 100
            print(f"ğŸ‰ æˆåŠŸï¼FNO-RC ({result['final_test_loss']:.6f}) ä¼˜äºFNOåŸºå‡† ({fno_baseline:.6f})")
            print(f"ğŸ“ˆ ç›¸å¯¹äºFNOåŸºå‡†æ”¹è¿›: {improvement:.2f}%")
            
            if improvement > 35:
                print(f"ğŸ† ä¼˜ç§€ï¼æ¥è¿‘ç›®æ ‡43.76%æ”¹è¿›ï¼")
            elif improvement > 20:
                print(f"ğŸ”¥ è‰¯å¥½è¿›å±•ï¼")
            elif improvement > 5:
                print(f"âš¡ æœ‰æ”¹è¿›ä½†éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        else:
            degradation = (result['final_test_loss'] - fno_baseline) / fno_baseline * 100
            print(f"âŒ FNO-RC ({result['final_test_loss']:.6f}) åŠ£äºFNOåŸºå‡† ({fno_baseline:.6f})")
            print(f"ğŸ“‰ æ€§èƒ½ä¸‹é™: {degradation:.2f}%")
            print("ğŸ”§ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•æ¶æ„é—®é¢˜")
        
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = '/content/drive/MyDrive/FNO_RC_Experiments/'
    os.makedirs(results_dir, exist_ok=True)
    results_file = f'{results_dir}/correct_architecture_3d_comparison_{timestamp}.json'

    serializable_results = {}
    for name, result in results.items():
        serializable_results[name] = {
            'final_test_loss': float(result['final_test_loss']),
            'parameters': int(result['parameters']),
            'train_losses': [float(x) for x in result['train_losses']],
            'test_losses': [float(x) for x in result['test_losses']]
        }

    with open(results_file, 'w') as f:
        json.dump(serializable_results, f, indent=2)

    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    print("ğŸ‰ æ­£ç¡®æ¶æ„3Då¯¹æ¯”å®éªŒå®Œæˆï¼")
    print("\nğŸ“ æ­£ç¡®æ¶æ„è¦ç‚¹:")
    print("   âœ… åŸºäºfourier_3d_clean.pyçš„æˆç†ŸFNOç»“æ„")
    print("   âœ… å•ä¸€æƒé‡çŸ©é˜µï¼ˆä¸æ˜¯4ä¸ªï¼‰")
    print("   âœ… å®Œå…¨å¤åˆ¶2DæˆåŠŸçš„CFTæ®‹å·®é€»è¾‘")
    print("   âœ… ç®€åŒ–CFTè®¡ç®—ï¼ˆFFTè¿‘ä¼¼ï¼‰")
    print("   âœ… é›¶åˆå§‹åŒ–ç¡®ä¿è®­ç»ƒç¨³å®šæ€§")

if __name__ == "__main__":
    main()
